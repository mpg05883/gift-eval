{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates dataset configurations using the datasets in [GIFT-Eval](https://github.com/SalesforceAIResearch/gift-eval) to train the models proposed in the [Ensemble TEMPO slides](https://docs.google.com/presentation/d/1GxL_qUQKizv5C_RPzxYiJjxJSPD6-81x1VPOxxYXAl0/edit?slide=id.g35d6bf22e47_0_10#slide=id.g35d6bf22e47_0_10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble TEMPO will have models at three different granularities:\n",
    "- **General** \n",
    "  - Three models across three forecasting terms (short, medium, and long)\n",
    "- **Domain-specific** \n",
    "  - 15 models across seven domains and three forecasting terms\n",
    "- **Dataset-specific** \n",
    "  - 97+ models across each dataset\n",
    "  - **Note:**: Dataset-specific models will only be trained on the train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each split (pretraining and train-test), we want to get the datasets we want to use for the \n",
    "- Three general models\n",
    "- 15 domain-specific models\n",
    "- 97+ dataset-specific models (only for train-test)\n",
    "\n",
    "First, we'll get the dataset configurations for the pretraining split. Then, we'll get the dataset configurations for train-test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretraining split's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique pretrain datasets: 152\n",
      "Number of unique pretrain terms: 3\n",
      "Total number of pretrain datasets: 456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_series</th>\n",
       "      <th>target_dim</th>\n",
       "      <th>_min_series_length</th>\n",
       "      <th>sum_series_length</th>\n",
       "      <th>prediction_length</th>\n",
       "      <th>windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bull</td>\n",
       "      <td>short</td>\n",
       "      <td>H</td>\n",
       "      <td>Energy</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>17544</td>\n",
       "      <td>719304</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bull</td>\n",
       "      <td>medium</td>\n",
       "      <td>H</td>\n",
       "      <td>Energy</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>17544</td>\n",
       "      <td>719304</td>\n",
       "      <td>480</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bull</td>\n",
       "      <td>long</td>\n",
       "      <td>H</td>\n",
       "      <td>Energy</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>17544</td>\n",
       "      <td>719304</td>\n",
       "      <td>720</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cmip6_1885</td>\n",
       "      <td>short</td>\n",
       "      <td>6H</td>\n",
       "      <td>Climate</td>\n",
       "      <td>434176</td>\n",
       "      <td>53</td>\n",
       "      <td>7300</td>\n",
       "      <td>3169484800</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cmip6_1885</td>\n",
       "      <td>medium</td>\n",
       "      <td>6H</td>\n",
       "      <td>Climate</td>\n",
       "      <td>434176</td>\n",
       "      <td>53</td>\n",
       "      <td>7300</td>\n",
       "      <td>3169484800</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name    term freq   domain  num_series  target_dim   \n",
       "0        bull   short    H   Energy          41           1  \\\n",
       "1        bull  medium    H   Energy          41           1   \n",
       "2        bull    long    H   Energy          41           1   \n",
       "3  cmip6_1885   short   6H  Climate      434176          53   \n",
       "4  cmip6_1885  medium   6H  Climate      434176          53   \n",
       "\n",
       "   _min_series_length  sum_series_length  prediction_length  windows  \n",
       "0               17544             719304                 48       20  \n",
       "1               17544             719304                480        4  \n",
       "2               17544             719304                720        3  \n",
       "3                7300         3169484800                 48       16  \n",
       "4                7300         3169484800                480        2  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils import SplitType\n",
    "\n",
    "split_type = SplitType.PRETRAIN\n",
    "metadata_path = Path(\"resources\") / split_type / \"metadata.csv\"\n",
    "\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Number of unique {split_type} datasets: {df['name'].nunique()}\")\n",
    "print(f\"Number of unique {split_type} terms: {df['term'].nunique()}\")\n",
    "print(f\"Total number of {split_type} datasets: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View all of the unique forecasting terms and count the number of datasets that belong to each term.\n",
    "- Each forecasting term multiplies the original prediction length by a multipler:\n",
    "  - \"long\" multiplies the original prediction length by 15\n",
    "  - \"medium\" multiplies the original prediction length by 10  \n",
    "  - \"short\" multiplies the original prediction length by 1 (no change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms: short, medium, long\n",
      "Number of unique terms: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>short</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     term  count\n",
       "0    long    152\n",
       "1  medium    152\n",
       "2   short    152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_count_df(\n",
    "    df: pd.DataFrame,\n",
    "    columns: list[str],\n",
    "    ascending: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Counts the number of unique combinations of all unique values in the\n",
    "    specified columns of the given a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        columns (list[str]): A list of column names to group by.\n",
    "        ascending (bool, optional): If True, sort the result in ascending order\n",
    "            of count. Defaults to False (descending order).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the grouped columns and a 'count'\n",
    "            column, sorted by count.\n",
    "    \"\"\"\n",
    "    count_df = df.groupby(columns).size().reset_index(name=\"count\")\n",
    "    return count_df.sort_values(by=\"count\", ascending=ascending).reset_index(drop=True)\n",
    "\n",
    "\n",
    "term_counts = get_count_df(df, columns=[\"term\"], ascending=False)\n",
    "\n",
    "terms = df[\"term\"].unique()\n",
    "\n",
    "print(f'Terms: {\", \".join(terms)}')\n",
    "print(f\"Number of unique terms: {len(term_counts)}\")\n",
    "display(term_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each term and its associated dataset names to a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of general configurations: 3\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "general_document = []\n",
    "\n",
    "for term in terms:\n",
    "    names = df[df[\"term\"] == term][\"name\"].tolist()\n",
    "\n",
    "    # Add a mapping for each term\n",
    "    general_document.append(\n",
    "        {\n",
    "            \"term\": term,\n",
    "            \"names\": names,\n",
    "        }\n",
    "    )\n",
    "\n",
    "documents = [general_document]\n",
    "\n",
    "num_general_configs = len(general_document)\n",
    "\n",
    "yaml_path = Path(\"configs\") / split_type / \"datasets.yaml\"\n",
    "\n",
    "print(f\"Number of general configurations: {num_general_configs}\")\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump_all(documents, file, explicit_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the YAML file to ensure the configurations were saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 1\n",
      "--- Document 1 ---\n",
      "- names:\n",
      "  - bull\n",
      "  - cmip6_1885\n",
      "  - era5_1991\n",
      "  - SHMETRO\n",
      "  - era5_2006\n",
      "  - BEIJING_SUBWAY_30MIN\n",
      "  - gfc12_load\n",
      "  - buildings_900k\n",
      "  - london_smart_meters_with_missing\n",
      "  - residential_pv_power\n",
      "  - PEMS_BAY\n",
      "  - wind_power\n",
      "  - cmip6_1975\n",
      "  - elecdemand\n",
      "  - wiki-rolling_nips\n",
      "  - spain\n",
      "  - cdc_fluview_who_nrevss\n",
      "  - covid_mobility\n",
      "  - monash_m3_quarterly\n",
      "  - era5_2015\n",
      "  - alibaba_cluster_trace_2018\n",
      "  - cmip6_1930\n",
      "  - uber_tlc_hourly\n",
      "  - era5_2012\n",
      "  - cmip6_1940\n",
      "  - bdg-2_rat\n",
      "  - era5_2018\n",
      "  - largest_2020\n",
      "  - cmip6_1875\n",
      "  - cmip6_1905\n",
      "  - borg_cluster_data_2011\n",
      "  - tourism_yearly\n",
      "  - traffic_weekly\n",
      "  - largest_2018\n",
      "  - PEMS07\n",
      "  - era5_2001\n",
      "  - cif_2016_6\n",
      "  - era5_1996\n",
      "  - bdg-2_panther\n",
      "  - cmip6_1985\n",
      "  - monash_m3_yearly\n",
      "  - bitcoin_with_missing\n",
      "  - era5_1998\n",
      "  - era5_1992\n",
      "  - favorita_sales\n",
      "  - cmip6_1965\n",
      "  - hog\n",
      "  - era5_2005\n",
      "  - cmip6_1850\n",
      "  - PEMS03\n",
      "  - cmip6_1920\n",
      "  - covid19_energy\n",
      "  - LOS_LOOP\n",
      "  - cmip6_1895\n",
      "  - tourism_quarterly\n",
      "  - extended_web_traffic_with_missing\n",
      "  - subseasonal_precip\n",
      "  - cmip6_2005\n",
      "  - era5_2016\n",
      "  - azure_vm_traces_2017\n",
      "  - taxi_30min\n",
      "  - favorita_transactions\n",
      "  - smart\n",
      "  - kdd2022\n",
      "  - gfc17_load\n",
      "  - cif_2016_12\n",
      "  - era5_2011\n",
      "  - borealis\n",
      "  - godaddy\n",
      "  - cmip6_1995\n",
      "  - vehicle_trips_with_missing\n",
      "  - nn5_weekly\n",
      "  - era5_2002\n",
      "  - pedestrian_counts\n",
      "  - era5_2008\n",
      "  - PEMS04\n",
      "  - cmip6_1950\n",
      "  - ideal\n",
      "  - cmip6_1865\n",
      "  - residential_load_power\n",
      "  - era5_1995\n",
      "  - cmip6_1915\n",
      "  - cmip6_1855\n",
      "  - beijing_air_quality\n",
      "  - era5_2000\n",
      "  - cmip6_1925\n",
      "  - china_air_quality\n",
      "  - kaggle_web_traffic_weekly\n",
      "  - cdc_fluview_ilinet\n",
      "  - era5_1997\n",
      "  - cmip6_1960\n",
      "  - cmip6_2000\n",
      "  - era5_2013\n",
      "  - nn5_daily_with_missing\n",
      "  - largest_2021\n",
      "  - cmip6_1890\n",
      "  - largest_2019\n",
      "  - sunspot_with_missing\n",
      "  - m5\n",
      "  - elf\n",
      "  - era5_1989\n",
      "  - cmip6_1990\n",
      "  - cockatoo\n",
      "  - era5_2014\n",
      "  - cmip6_1860\n",
      "  - era5_1990\n",
      "  - fred_md\n",
      "  - cmip6_1910\n",
      "  - monash_m3_other\n",
      "  - era5_2007\n",
      "  - cmip6_1955\n",
      "  - subseasonal\n",
      "  - traffic_hourly\n",
      "  - monash_m3_monthly\n",
      "  - cmip6_2010\n",
      "  - era5_2009\n",
      "  - wind_farms_with_missing\n",
      "  - era5_2003\n",
      "  - gfc14_load\n",
      "  - project_tycho\n",
      "  - bdg-2_bear\n",
      "  - m1_monthly\n",
      "  - cmip6_1880\n",
      "  - era5_1994\n",
      "  - era5_2010\n",
      "  - cmip6_1935\n",
      "  - australian_electricity_demand\n",
      "  - m1_quarterly\n",
      "  - pdb\n",
      "  - lcl\n",
      "  - cmip6_1970\n",
      "  - oikolab_weather\n",
      "  - cmip6_1870\n",
      "  - cmip6_1900\n",
      "  - largest_2017\n",
      "  - tourism_monthly\n",
      "  - HZMETRO\n",
      "  - era5_2017\n",
      "  - cmip6_1945\n",
      "  - uber_tlc_daily\n",
      "  - era5_1993\n",
      "  - era5_1999\n",
      "  - cmip6_1980\n",
      "  - weather\n",
      "  - rideshare_with_missing\n",
      "  - PEMS08\n",
      "  - era5_2004\n",
      "  - sceaux\n",
      "  - solar_power\n",
      "  - m1_yearly\n",
      "  - bdg-2_fox\n",
      "  - Q-TRAFFIC\n",
      "  term: short\n",
      "- names:\n",
      "  - bull\n",
      "  - cmip6_1885\n",
      "  - era5_1991\n",
      "  - SHMETRO\n",
      "  - era5_2006\n",
      "  - BEIJING_SUBWAY_30MIN\n",
      "  - gfc12_load\n",
      "  - buildings_900k\n",
      "  - london_smart_meters_with_missing\n",
      "  - residential_pv_power\n",
      "  - PEMS_BAY\n",
      "  - wind_power\n",
      "  - cmip6_1975\n",
      "  - elecdemand\n",
      "  - wiki-rolling_nips\n",
      "  - spain\n",
      "  - cdc_fluview_who_nrevss\n",
      "  - covid_mobility\n",
      "  - monash_m3_quarterly\n",
      "  - era5_2015\n",
      "  - alibaba_cluster_trace_2018\n",
      "  - cmip6_1930\n",
      "  - uber_tlc_hourly\n",
      "  - era5_2012\n",
      "  - cmip6_1940\n",
      "  - bdg-2_rat\n",
      "  - era5_2018\n",
      "  - largest_2020\n",
      "  - cmip6_1875\n",
      "  - cmip6_1905\n",
      "  - borg_cluster_data_2011\n",
      "  - tourism_yearly\n",
      "  - traffic_weekly\n",
      "  - largest_2018\n",
      "  - PEMS07\n",
      "  - era5_2001\n",
      "  - cif_2016_6\n",
      "  - era5_1996\n",
      "  - bdg-2_panther\n",
      "  - cmip6_1985\n",
      "  - monash_m3_yearly\n",
      "  - bitcoin_with_missing\n",
      "  - era5_1998\n",
      "  - era5_1992\n",
      "  - favorita_sales\n",
      "  - cmip6_1965\n",
      "  - hog\n",
      "  - era5_2005\n",
      "  - cmip6_1850\n",
      "  - PEMS03\n",
      "  - cmip6_1920\n",
      "  - covid19_energy\n",
      "  - LOS_LOOP\n",
      "  - cmip6_1895\n",
      "  - tourism_quarterly\n",
      "  - extended_web_traffic_with_missing\n",
      "  - subseasonal_precip\n",
      "  - cmip6_2005\n",
      "  - era5_2016\n",
      "  - azure_vm_traces_2017\n",
      "  - taxi_30min\n",
      "  - favorita_transactions\n",
      "  - smart\n",
      "  - kdd2022\n",
      "  - gfc17_load\n",
      "  - cif_2016_12\n",
      "  - era5_2011\n",
      "  - borealis\n",
      "  - godaddy\n",
      "  - cmip6_1995\n",
      "  - vehicle_trips_with_missing\n",
      "  - nn5_weekly\n",
      "  - era5_2002\n",
      "  - pedestrian_counts\n",
      "  - era5_2008\n",
      "  - PEMS04\n",
      "  - cmip6_1950\n",
      "  - ideal\n",
      "  - cmip6_1865\n",
      "  - residential_load_power\n",
      "  - era5_1995\n",
      "  - cmip6_1915\n",
      "  - cmip6_1855\n",
      "  - beijing_air_quality\n",
      "  - era5_2000\n",
      "  - cmip6_1925\n",
      "  - china_air_quality\n",
      "  - kaggle_web_traffic_weekly\n",
      "  - cdc_fluview_ilinet\n",
      "  - era5_1997\n",
      "  - cmip6_1960\n",
      "  - cmip6_2000\n",
      "  - era5_2013\n",
      "  - nn5_daily_with_missing\n",
      "  - largest_2021\n",
      "  - cmip6_1890\n",
      "  - largest_2019\n",
      "  - sunspot_with_missing\n",
      "  - m5\n",
      "  - elf\n",
      "  - era5_1989\n",
      "  - cmip6_1990\n",
      "  - cockatoo\n",
      "  - era5_2014\n",
      "  - cmip6_1860\n",
      "  - era5_1990\n",
      "  - fred_md\n",
      "  - cmip6_1910\n",
      "  - monash_m3_other\n",
      "  - era5_2007\n",
      "  - cmip6_1955\n",
      "  - subseasonal\n",
      "  - traffic_hourly\n",
      "  - monash_m3_monthly\n",
      "  - cmip6_2010\n",
      "  - era5_2009\n",
      "  - wind_farms_with_missing\n",
      "  - era5_2003\n",
      "  - gfc14_load\n",
      "  - project_tycho\n",
      "  - bdg-2_bear\n",
      "  - m1_monthly\n",
      "  - cmip6_1880\n",
      "  - era5_1994\n",
      "  - era5_2010\n",
      "  - cmip6_1935\n",
      "  - australian_electricity_demand\n",
      "  - m1_quarterly\n",
      "  - pdb\n",
      "  - lcl\n",
      "  - cmip6_1970\n",
      "  - oikolab_weather\n",
      "  - cmip6_1870\n",
      "  - cmip6_1900\n",
      "  - largest_2017\n",
      "  - tourism_monthly\n",
      "  - HZMETRO\n",
      "  - era5_2017\n",
      "  - cmip6_1945\n",
      "  - uber_tlc_daily\n",
      "  - era5_1993\n",
      "  - era5_1999\n",
      "  - cmip6_1980\n",
      "  - weather\n",
      "  - rideshare_with_missing\n",
      "  - PEMS08\n",
      "  - era5_2004\n",
      "  - sceaux\n",
      "  - solar_power\n",
      "  - m1_yearly\n",
      "  - bdg-2_fox\n",
      "  - Q-TRAFFIC\n",
      "  term: medium\n",
      "- names:\n",
      "  - bull\n",
      "  - cmip6_1885\n",
      "  - era5_1991\n",
      "  - SHMETRO\n",
      "  - era5_2006\n",
      "  - BEIJING_SUBWAY_30MIN\n",
      "  - gfc12_load\n",
      "  - buildings_900k\n",
      "  - london_smart_meters_with_missing\n",
      "  - residential_pv_power\n",
      "  - PEMS_BAY\n",
      "  - wind_power\n",
      "  - cmip6_1975\n",
      "  - elecdemand\n",
      "  - wiki-rolling_nips\n",
      "  - spain\n",
      "  - cdc_fluview_who_nrevss\n",
      "  - covid_mobility\n",
      "  - monash_m3_quarterly\n",
      "  - era5_2015\n",
      "  - alibaba_cluster_trace_2018\n",
      "  - cmip6_1930\n",
      "  - uber_tlc_hourly\n",
      "  - era5_2012\n",
      "  - cmip6_1940\n",
      "  - bdg-2_rat\n",
      "  - era5_2018\n",
      "  - largest_2020\n",
      "  - cmip6_1875\n",
      "  - cmip6_1905\n",
      "  - borg_cluster_data_2011\n",
      "  - tourism_yearly\n",
      "  - traffic_weekly\n",
      "  - largest_2018\n",
      "  - PEMS07\n",
      "  - era5_2001\n",
      "  - cif_2016_6\n",
      "  - era5_1996\n",
      "  - bdg-2_panther\n",
      "  - cmip6_1985\n",
      "  - monash_m3_yearly\n",
      "  - bitcoin_with_missing\n",
      "  - era5_1998\n",
      "  - era5_1992\n",
      "  - favorita_sales\n",
      "  - cmip6_1965\n",
      "  - hog\n",
      "  - era5_2005\n",
      "  - cmip6_1850\n",
      "  - PEMS03\n",
      "  - cmip6_1920\n",
      "  - covid19_energy\n",
      "  - LOS_LOOP\n",
      "  - cmip6_1895\n",
      "  - tourism_quarterly\n",
      "  - extended_web_traffic_with_missing\n",
      "  - subseasonal_precip\n",
      "  - cmip6_2005\n",
      "  - era5_2016\n",
      "  - azure_vm_traces_2017\n",
      "  - taxi_30min\n",
      "  - favorita_transactions\n",
      "  - smart\n",
      "  - kdd2022\n",
      "  - gfc17_load\n",
      "  - cif_2016_12\n",
      "  - era5_2011\n",
      "  - borealis\n",
      "  - godaddy\n",
      "  - cmip6_1995\n",
      "  - vehicle_trips_with_missing\n",
      "  - nn5_weekly\n",
      "  - era5_2002\n",
      "  - pedestrian_counts\n",
      "  - era5_2008\n",
      "  - PEMS04\n",
      "  - cmip6_1950\n",
      "  - ideal\n",
      "  - cmip6_1865\n",
      "  - residential_load_power\n",
      "  - era5_1995\n",
      "  - cmip6_1915\n",
      "  - cmip6_1855\n",
      "  - beijing_air_quality\n",
      "  - era5_2000\n",
      "  - cmip6_1925\n",
      "  - china_air_quality\n",
      "  - kaggle_web_traffic_weekly\n",
      "  - cdc_fluview_ilinet\n",
      "  - era5_1997\n",
      "  - cmip6_1960\n",
      "  - cmip6_2000\n",
      "  - era5_2013\n",
      "  - nn5_daily_with_missing\n",
      "  - largest_2021\n",
      "  - cmip6_1890\n",
      "  - largest_2019\n",
      "  - sunspot_with_missing\n",
      "  - m5\n",
      "  - elf\n",
      "  - era5_1989\n",
      "  - cmip6_1990\n",
      "  - cockatoo\n",
      "  - era5_2014\n",
      "  - cmip6_1860\n",
      "  - era5_1990\n",
      "  - fred_md\n",
      "  - cmip6_1910\n",
      "  - monash_m3_other\n",
      "  - era5_2007\n",
      "  - cmip6_1955\n",
      "  - subseasonal\n",
      "  - traffic_hourly\n",
      "  - monash_m3_monthly\n",
      "  - cmip6_2010\n",
      "  - era5_2009\n",
      "  - wind_farms_with_missing\n",
      "  - era5_2003\n",
      "  - gfc14_load\n",
      "  - project_tycho\n",
      "  - bdg-2_bear\n",
      "  - m1_monthly\n",
      "  - cmip6_1880\n",
      "  - era5_1994\n",
      "  - era5_2010\n",
      "  - cmip6_1935\n",
      "  - australian_electricity_demand\n",
      "  - m1_quarterly\n",
      "  - pdb\n",
      "  - lcl\n",
      "  - cmip6_1970\n",
      "  - oikolab_weather\n",
      "  - cmip6_1870\n",
      "  - cmip6_1900\n",
      "  - largest_2017\n",
      "  - tourism_monthly\n",
      "  - HZMETRO\n",
      "  - era5_2017\n",
      "  - cmip6_1945\n",
      "  - uber_tlc_daily\n",
      "  - era5_1993\n",
      "  - era5_1999\n",
      "  - cmip6_1980\n",
      "  - weather\n",
      "  - rideshare_with_missing\n",
      "  - PEMS08\n",
      "  - era5_2004\n",
      "  - sceaux\n",
      "  - solar_power\n",
      "  - m1_yearly\n",
      "  - bdg-2_fox\n",
      "  - Q-TRAFFIC\n",
      "  term: long\n",
      "\n",
      "Config 1:\n",
      "  Term: short\n",
      "  Number of names: 152\n",
      "  Names: bull, cmip6_1885, era5_1991, SHMETRO, era5_2006, BEIJING_SUBWAY_30MIN, gfc12_load, buildings_900k, london_smart_meters_with_missing, residential_pv_power, PEMS_BAY, wind_power, cmip6_1975, elecdemand, wiki-rolling_nips, spain, cdc_fluview_who_nrevss, covid_mobility, monash_m3_quarterly, era5_2015, alibaba_cluster_trace_2018, cmip6_1930, uber_tlc_hourly, era5_2012, cmip6_1940, bdg-2_rat, era5_2018, largest_2020, cmip6_1875, cmip6_1905, borg_cluster_data_2011, tourism_yearly, traffic_weekly, largest_2018, PEMS07, era5_2001, cif_2016_6, era5_1996, bdg-2_panther, cmip6_1985, monash_m3_yearly, bitcoin_with_missing, era5_1998, era5_1992, favorita_sales, cmip6_1965, hog, era5_2005, cmip6_1850, PEMS03, cmip6_1920, covid19_energy, LOS_LOOP, cmip6_1895, tourism_quarterly, extended_web_traffic_with_missing, subseasonal_precip, cmip6_2005, era5_2016, azure_vm_traces_2017, taxi_30min, favorita_transactions, smart, kdd2022, gfc17_load, cif_2016_12, era5_2011, borealis, godaddy, cmip6_1995, vehicle_trips_with_missing, nn5_weekly, era5_2002, pedestrian_counts, era5_2008, PEMS04, cmip6_1950, ideal, cmip6_1865, residential_load_power, era5_1995, cmip6_1915, cmip6_1855, beijing_air_quality, era5_2000, cmip6_1925, china_air_quality, kaggle_web_traffic_weekly, cdc_fluview_ilinet, era5_1997, cmip6_1960, cmip6_2000, era5_2013, nn5_daily_with_missing, largest_2021, cmip6_1890, largest_2019, sunspot_with_missing, m5, elf, era5_1989, cmip6_1990, cockatoo, era5_2014, cmip6_1860, era5_1990, fred_md, cmip6_1910, monash_m3_other, era5_2007, cmip6_1955, subseasonal, traffic_hourly, monash_m3_monthly, cmip6_2010, era5_2009, wind_farms_with_missing, era5_2003, gfc14_load, project_tycho, bdg-2_bear, m1_monthly, cmip6_1880, era5_1994, era5_2010, cmip6_1935, australian_electricity_demand, m1_quarterly, pdb, lcl, cmip6_1970, oikolab_weather, cmip6_1870, cmip6_1900, largest_2017, tourism_monthly, HZMETRO, era5_2017, cmip6_1945, uber_tlc_daily, era5_1993, era5_1999, cmip6_1980, weather, rideshare_with_missing, PEMS08, era5_2004, sceaux, solar_power, m1_yearly, bdg-2_fox, Q-TRAFFIC\n",
      "\n",
      "Config 2:\n",
      "  Term: medium\n",
      "  Number of names: 152\n",
      "  Names: bull, cmip6_1885, era5_1991, SHMETRO, era5_2006, BEIJING_SUBWAY_30MIN, gfc12_load, buildings_900k, london_smart_meters_with_missing, residential_pv_power, PEMS_BAY, wind_power, cmip6_1975, elecdemand, wiki-rolling_nips, spain, cdc_fluview_who_nrevss, covid_mobility, monash_m3_quarterly, era5_2015, alibaba_cluster_trace_2018, cmip6_1930, uber_tlc_hourly, era5_2012, cmip6_1940, bdg-2_rat, era5_2018, largest_2020, cmip6_1875, cmip6_1905, borg_cluster_data_2011, tourism_yearly, traffic_weekly, largest_2018, PEMS07, era5_2001, cif_2016_6, era5_1996, bdg-2_panther, cmip6_1985, monash_m3_yearly, bitcoin_with_missing, era5_1998, era5_1992, favorita_sales, cmip6_1965, hog, era5_2005, cmip6_1850, PEMS03, cmip6_1920, covid19_energy, LOS_LOOP, cmip6_1895, tourism_quarterly, extended_web_traffic_with_missing, subseasonal_precip, cmip6_2005, era5_2016, azure_vm_traces_2017, taxi_30min, favorita_transactions, smart, kdd2022, gfc17_load, cif_2016_12, era5_2011, borealis, godaddy, cmip6_1995, vehicle_trips_with_missing, nn5_weekly, era5_2002, pedestrian_counts, era5_2008, PEMS04, cmip6_1950, ideal, cmip6_1865, residential_load_power, era5_1995, cmip6_1915, cmip6_1855, beijing_air_quality, era5_2000, cmip6_1925, china_air_quality, kaggle_web_traffic_weekly, cdc_fluview_ilinet, era5_1997, cmip6_1960, cmip6_2000, era5_2013, nn5_daily_with_missing, largest_2021, cmip6_1890, largest_2019, sunspot_with_missing, m5, elf, era5_1989, cmip6_1990, cockatoo, era5_2014, cmip6_1860, era5_1990, fred_md, cmip6_1910, monash_m3_other, era5_2007, cmip6_1955, subseasonal, traffic_hourly, monash_m3_monthly, cmip6_2010, era5_2009, wind_farms_with_missing, era5_2003, gfc14_load, project_tycho, bdg-2_bear, m1_monthly, cmip6_1880, era5_1994, era5_2010, cmip6_1935, australian_electricity_demand, m1_quarterly, pdb, lcl, cmip6_1970, oikolab_weather, cmip6_1870, cmip6_1900, largest_2017, tourism_monthly, HZMETRO, era5_2017, cmip6_1945, uber_tlc_daily, era5_1993, era5_1999, cmip6_1980, weather, rideshare_with_missing, PEMS08, era5_2004, sceaux, solar_power, m1_yearly, bdg-2_fox, Q-TRAFFIC\n",
      "\n",
      "Config 3:\n",
      "  Term: long\n",
      "  Number of names: 152\n",
      "  Names: bull, cmip6_1885, era5_1991, SHMETRO, era5_2006, BEIJING_SUBWAY_30MIN, gfc12_load, buildings_900k, london_smart_meters_with_missing, residential_pv_power, PEMS_BAY, wind_power, cmip6_1975, elecdemand, wiki-rolling_nips, spain, cdc_fluview_who_nrevss, covid_mobility, monash_m3_quarterly, era5_2015, alibaba_cluster_trace_2018, cmip6_1930, uber_tlc_hourly, era5_2012, cmip6_1940, bdg-2_rat, era5_2018, largest_2020, cmip6_1875, cmip6_1905, borg_cluster_data_2011, tourism_yearly, traffic_weekly, largest_2018, PEMS07, era5_2001, cif_2016_6, era5_1996, bdg-2_panther, cmip6_1985, monash_m3_yearly, bitcoin_with_missing, era5_1998, era5_1992, favorita_sales, cmip6_1965, hog, era5_2005, cmip6_1850, PEMS03, cmip6_1920, covid19_energy, LOS_LOOP, cmip6_1895, tourism_quarterly, extended_web_traffic_with_missing, subseasonal_precip, cmip6_2005, era5_2016, azure_vm_traces_2017, taxi_30min, favorita_transactions, smart, kdd2022, gfc17_load, cif_2016_12, era5_2011, borealis, godaddy, cmip6_1995, vehicle_trips_with_missing, nn5_weekly, era5_2002, pedestrian_counts, era5_2008, PEMS04, cmip6_1950, ideal, cmip6_1865, residential_load_power, era5_1995, cmip6_1915, cmip6_1855, beijing_air_quality, era5_2000, cmip6_1925, china_air_quality, kaggle_web_traffic_weekly, cdc_fluview_ilinet, era5_1997, cmip6_1960, cmip6_2000, era5_2013, nn5_daily_with_missing, largest_2021, cmip6_1890, largest_2019, sunspot_with_missing, m5, elf, era5_1989, cmip6_1990, cockatoo, era5_2014, cmip6_1860, era5_1990, fred_md, cmip6_1910, monash_m3_other, era5_2007, cmip6_1955, subseasonal, traffic_hourly, monash_m3_monthly, cmip6_2010, era5_2009, wind_farms_with_missing, era5_2003, gfc14_load, project_tycho, bdg-2_bear, m1_monthly, cmip6_1880, era5_1994, era5_2010, cmip6_1935, australian_electricity_demand, m1_quarterly, pdb, lcl, cmip6_1970, oikolab_weather, cmip6_1870, cmip6_1900, largest_2017, tourism_monthly, HZMETRO, era5_2017, cmip6_1945, uber_tlc_daily, era5_1993, era5_1999, cmip6_1980, weather, rideshare_with_missing, PEMS08, era5_2004, sceaux, solar_power, m1_yearly, bdg-2_fox, Q-TRAFFIC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(yaml_path, \"r\") as file:\n",
    "    documents = list(yaml.load_all(file, Loader=yaml.SafeLoader))\n",
    "\n",
    "num_documents = len(documents)\n",
    "print(f\"Number of documents loaded: {num_documents}\")\n",
    "\n",
    "for i, document in enumerate(documents, 1):\n",
    "    print(f\"--- Document {i} ---\")\n",
    "    print(yaml.dump(document, sort_keys=False))\n",
    "\n",
    "# Access the general configurations\n",
    "general_configs = documents[0]\n",
    "\n",
    "assert len(general_configs) == 3\n",
    "\n",
    "for i, config in enumerate(general_configs):\n",
    "    print(f\"Config {i+1}:\")\n",
    "\n",
    "    term = config[\"term\"]\n",
    "    print(f\"  Term: {term}\")\n",
    "\n",
    "    num_names = len(config[\"names\"])\n",
    "    term_mask = term_counts[\"term\"] == term\n",
    "    assert num_names == term_counts.loc[term_mask, \"count\"].iloc[0]\n",
    "\n",
    "    print(f\"  Number of names: {num_names}\")\n",
    "    print(f\"  Names: {', '.join(config['names'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain-Specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View all of the unique domain-term combinations and count the number of datasets that belong to each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domains: Energy, Climate, Transport, Web, Healthcare, Econ/Fin, CloudOps, Sales, Nature\n",
      "Terms: short, medium, long\n",
      "Number of unique domain-term combinations: 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>short</th>\n",
       "      <th>medium</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Climate</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CloudOps</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Econ/Fin</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthcare</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nature</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transport</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       domain  short  medium  long\n",
       "0     Climate     67      67    67\n",
       "1    CloudOps      3       3     3\n",
       "2    Econ/Fin     17      17    17\n",
       "3      Energy     28      28    28\n",
       "4  Healthcare      3       3     3\n",
       "5      Nature      3       3     3\n",
       "6       Sales      3       3     3\n",
       "7   Transport     25      25    25\n",
       "8         Web      3       3     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domains, terms = df[\"domain\"].unique(), df[\"term\"].unique()\n",
    "\n",
    "domain_term_counts = get_count_df(\n",
    "    df,\n",
    "    columns=[\"domain\", \"term\"],\n",
    "    ascending=False,\n",
    ")\n",
    "\n",
    "# Convert each term into its own column\n",
    "pivoted_df = domain_term_counts.pivot(\n",
    "    index=\"domain\",\n",
    "    columns=\"term\",\n",
    "    values=\"count\",\n",
    ").reset_index()\n",
    "\n",
    "# Remove old \"term\" column\n",
    "pivoted_df.columns.name = None\n",
    "\n",
    "# Reorder columns\n",
    "pivoted_df = pivoted_df[\n",
    "    [\n",
    "        \"domain\",\n",
    "        \"short\",\n",
    "        \"medium\",\n",
    "        \"long\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(f'Domains: {\", \".join(domains)}')\n",
    "print(f'Terms: {\", \".join(terms)}')\n",
    "print(f\"Number of unique domain-term combinations: {len(domain_term_counts)}\")\n",
    "display(pivoted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add each domain-term combination's domain, term, and dataset names to the yaml file.\n",
    "- We'll only create short groups for the following domains because they don't have any medium or long datasets in the train-test split:\n",
    "  - Econ/Fin\n",
    "  - Healthcare\n",
    "  - Sales\n",
    "- We'll also create combined dataset configurations for the following domain pairs\n",
    "  - Web and CloudOps\n",
    "  - Nature and Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 'medium' for 'Healthcare'...\n",
      "Skipping 'long' for 'Healthcare'...\n",
      "Skipping 'medium' for 'Econ/Fin'...\n",
      "Skipping 'long' for 'Econ/Fin'...\n",
      "Skipping 'medium' for 'Sales'...\n",
      "Skipping 'long' for 'Sales'...\n",
      "Number of domain configs: 27\n"
     ]
    }
   ],
   "source": [
    "from utils import Domain\n",
    "\n",
    "excluded_domains = [\n",
    "    \"Econ/Fin\",\n",
    "    \"Healthcare\",\n",
    "    \"Sales\",\n",
    "]\n",
    "\n",
    "domain_document = []\n",
    "\n",
    "for domain in domains:\n",
    "\n",
    "    for term in terms:\n",
    "        # Exclude domains that only have short term datasets\n",
    "        if domain in excluded_domains and term != \"short\":\n",
    "            print(f\"Skipping '{term}' for '{domain}'...\")\n",
    "            continue\n",
    "\n",
    "        domain_mask, term_mask = df[\"domain\"] == domain, df[\"term\"] == term\n",
    "        filtered_df = df[domain_mask & term_mask]\n",
    "\n",
    "        names = filtered_df[\"name\"].tolist()\n",
    "\n",
    "        if not names:\n",
    "            print(f\"No datasets found for domain '{domain}' and term '{term}'\")\n",
    "            continue\n",
    "\n",
    "        # Add a mapping for each domain-term combination\n",
    "        domain_document.append(\n",
    "            {\n",
    "                \"domain\": domain,\n",
    "                \"term\": term,\n",
    "                \"names\": names,\n",
    "            }\n",
    "        )\n",
    "\n",
    "domain_pairs = [\n",
    "    (Domain.WEB, Domain.CLOUDOPS),\n",
    "    (Domain.NATURE, Domain.CLIMATE),\n",
    "]\n",
    "\n",
    "# Add custom domain pairs\n",
    "for domain_pair in domain_pairs:\n",
    "    num_short, num_medium, num_long = (0,) * 3\n",
    "    for term in terms:\n",
    "        domain_1, domain_2 = domain_pair\n",
    "        domain_mask = df[\"domain\"].isin([domain_1, domain_2])\n",
    "        term_mask = df[\"term\"] == term\n",
    "\n",
    "        filtered_df = df[domain_mask & term_mask]\n",
    "        names = filtered_df[\"name\"].tolist()\n",
    "\n",
    "        if not names:\n",
    "            print(f\"No datasets found for domain '{domain}' and term '{term}'\")\n",
    "            continue\n",
    "\n",
    "        if term == \"short\":\n",
    "            num_short = len(names)\n",
    "        elif term == \"medium\":\n",
    "            num_medium = len(names)\n",
    "        else:\n",
    "            num_long = len(names)\n",
    "\n",
    "        # Add a mapping for each domain-term combination\n",
    "        domain_document.append(\n",
    "            {\n",
    "                \"domain\": f\"{domain_1},{domain_2}\",\n",
    "                \"term\": term,\n",
    "                \"names\": names,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    new_row = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"domain\": f\"{domain_1},{domain_2}\",\n",
    "                \"short\": num_short,\n",
    "                \"medium\": num_medium,\n",
    "                \"long\": num_long,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pivoted_df = pd.concat([pivoted_df, new_row], ignore_index=True)\n",
    "\n",
    "documents.append(domain_document)\n",
    "num_domain_configs = len(domain_document)\n",
    "print(f\"Number of domain configs: {num_domain_configs}\")\n",
    "\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump_all(\n",
    "        documents,\n",
    "        file,\n",
    "        explicit_start=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the YAML file to ensure the configurations were saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 2\n",
      "\n",
      "--- General Document ---\n",
      "Config 1 | Name: ['bull', 'cmip6_1885', 'era5_1991', 'SHMETRO', 'era5_2006', 'BEIJING_SUBWAY_30MIN', 'gfc12_load', 'buildings_900k', 'london_smart_meters_with_missing', 'residential_pv_power', 'PEMS_BAY', 'wind_power', 'cmip6_1975', 'elecdemand', 'wiki-rolling_nips', 'spain', 'cdc_fluview_who_nrevss', 'covid_mobility', 'monash_m3_quarterly', 'era5_2015', 'alibaba_cluster_trace_2018', 'cmip6_1930', 'uber_tlc_hourly', 'era5_2012', 'cmip6_1940', 'bdg-2_rat', 'era5_2018', 'largest_2020', 'cmip6_1875', 'cmip6_1905', 'borg_cluster_data_2011', 'tourism_yearly', 'traffic_weekly', 'largest_2018', 'PEMS07', 'era5_2001', 'cif_2016_6', 'era5_1996', 'bdg-2_panther', 'cmip6_1985', 'monash_m3_yearly', 'bitcoin_with_missing', 'era5_1998', 'era5_1992', 'favorita_sales', 'cmip6_1965', 'hog', 'era5_2005', 'cmip6_1850', 'PEMS03', 'cmip6_1920', 'covid19_energy', 'LOS_LOOP', 'cmip6_1895', 'tourism_quarterly', 'extended_web_traffic_with_missing', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'azure_vm_traces_2017', 'taxi_30min', 'favorita_transactions', 'smart', 'kdd2022', 'gfc17_load', 'cif_2016_12', 'era5_2011', 'borealis', 'godaddy', 'cmip6_1995', 'vehicle_trips_with_missing', 'nn5_weekly', 'era5_2002', 'pedestrian_counts', 'era5_2008', 'PEMS04', 'cmip6_1950', 'ideal', 'cmip6_1865', 'residential_load_power', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'beijing_air_quality', 'era5_2000', 'cmip6_1925', 'china_air_quality', 'kaggle_web_traffic_weekly', 'cdc_fluview_ilinet', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'nn5_daily_with_missing', 'largest_2021', 'cmip6_1890', 'largest_2019', 'sunspot_with_missing', 'm5', 'elf', 'era5_1989', 'cmip6_1990', 'cockatoo', 'era5_2014', 'cmip6_1860', 'era5_1990', 'fred_md', 'cmip6_1910', 'monash_m3_other', 'era5_2007', 'cmip6_1955', 'subseasonal', 'traffic_hourly', 'monash_m3_monthly', 'cmip6_2010', 'era5_2009', 'wind_farms_with_missing', 'era5_2003', 'gfc14_load', 'project_tycho', 'bdg-2_bear', 'm1_monthly', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'australian_electricity_demand', 'm1_quarterly', 'pdb', 'lcl', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'largest_2017', 'tourism_monthly', 'HZMETRO', 'era5_2017', 'cmip6_1945', 'uber_tlc_daily', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'rideshare_with_missing', 'PEMS08', 'era5_2004', 'sceaux', 'solar_power', 'm1_yearly', 'bdg-2_fox', 'Q-TRAFFIC'], Term: short\n",
      "Config 2 | Name: ['bull', 'cmip6_1885', 'era5_1991', 'SHMETRO', 'era5_2006', 'BEIJING_SUBWAY_30MIN', 'gfc12_load', 'buildings_900k', 'london_smart_meters_with_missing', 'residential_pv_power', 'PEMS_BAY', 'wind_power', 'cmip6_1975', 'elecdemand', 'wiki-rolling_nips', 'spain', 'cdc_fluview_who_nrevss', 'covid_mobility', 'monash_m3_quarterly', 'era5_2015', 'alibaba_cluster_trace_2018', 'cmip6_1930', 'uber_tlc_hourly', 'era5_2012', 'cmip6_1940', 'bdg-2_rat', 'era5_2018', 'largest_2020', 'cmip6_1875', 'cmip6_1905', 'borg_cluster_data_2011', 'tourism_yearly', 'traffic_weekly', 'largest_2018', 'PEMS07', 'era5_2001', 'cif_2016_6', 'era5_1996', 'bdg-2_panther', 'cmip6_1985', 'monash_m3_yearly', 'bitcoin_with_missing', 'era5_1998', 'era5_1992', 'favorita_sales', 'cmip6_1965', 'hog', 'era5_2005', 'cmip6_1850', 'PEMS03', 'cmip6_1920', 'covid19_energy', 'LOS_LOOP', 'cmip6_1895', 'tourism_quarterly', 'extended_web_traffic_with_missing', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'azure_vm_traces_2017', 'taxi_30min', 'favorita_transactions', 'smart', 'kdd2022', 'gfc17_load', 'cif_2016_12', 'era5_2011', 'borealis', 'godaddy', 'cmip6_1995', 'vehicle_trips_with_missing', 'nn5_weekly', 'era5_2002', 'pedestrian_counts', 'era5_2008', 'PEMS04', 'cmip6_1950', 'ideal', 'cmip6_1865', 'residential_load_power', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'beijing_air_quality', 'era5_2000', 'cmip6_1925', 'china_air_quality', 'kaggle_web_traffic_weekly', 'cdc_fluview_ilinet', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'nn5_daily_with_missing', 'largest_2021', 'cmip6_1890', 'largest_2019', 'sunspot_with_missing', 'm5', 'elf', 'era5_1989', 'cmip6_1990', 'cockatoo', 'era5_2014', 'cmip6_1860', 'era5_1990', 'fred_md', 'cmip6_1910', 'monash_m3_other', 'era5_2007', 'cmip6_1955', 'subseasonal', 'traffic_hourly', 'monash_m3_monthly', 'cmip6_2010', 'era5_2009', 'wind_farms_with_missing', 'era5_2003', 'gfc14_load', 'project_tycho', 'bdg-2_bear', 'm1_monthly', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'australian_electricity_demand', 'm1_quarterly', 'pdb', 'lcl', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'largest_2017', 'tourism_monthly', 'HZMETRO', 'era5_2017', 'cmip6_1945', 'uber_tlc_daily', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'rideshare_with_missing', 'PEMS08', 'era5_2004', 'sceaux', 'solar_power', 'm1_yearly', 'bdg-2_fox', 'Q-TRAFFIC'], Term: medium\n",
      "Config 3 | Name: ['bull', 'cmip6_1885', 'era5_1991', 'SHMETRO', 'era5_2006', 'BEIJING_SUBWAY_30MIN', 'gfc12_load', 'buildings_900k', 'london_smart_meters_with_missing', 'residential_pv_power', 'PEMS_BAY', 'wind_power', 'cmip6_1975', 'elecdemand', 'wiki-rolling_nips', 'spain', 'cdc_fluview_who_nrevss', 'covid_mobility', 'monash_m3_quarterly', 'era5_2015', 'alibaba_cluster_trace_2018', 'cmip6_1930', 'uber_tlc_hourly', 'era5_2012', 'cmip6_1940', 'bdg-2_rat', 'era5_2018', 'largest_2020', 'cmip6_1875', 'cmip6_1905', 'borg_cluster_data_2011', 'tourism_yearly', 'traffic_weekly', 'largest_2018', 'PEMS07', 'era5_2001', 'cif_2016_6', 'era5_1996', 'bdg-2_panther', 'cmip6_1985', 'monash_m3_yearly', 'bitcoin_with_missing', 'era5_1998', 'era5_1992', 'favorita_sales', 'cmip6_1965', 'hog', 'era5_2005', 'cmip6_1850', 'PEMS03', 'cmip6_1920', 'covid19_energy', 'LOS_LOOP', 'cmip6_1895', 'tourism_quarterly', 'extended_web_traffic_with_missing', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'azure_vm_traces_2017', 'taxi_30min', 'favorita_transactions', 'smart', 'kdd2022', 'gfc17_load', 'cif_2016_12', 'era5_2011', 'borealis', 'godaddy', 'cmip6_1995', 'vehicle_trips_with_missing', 'nn5_weekly', 'era5_2002', 'pedestrian_counts', 'era5_2008', 'PEMS04', 'cmip6_1950', 'ideal', 'cmip6_1865', 'residential_load_power', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'beijing_air_quality', 'era5_2000', 'cmip6_1925', 'china_air_quality', 'kaggle_web_traffic_weekly', 'cdc_fluview_ilinet', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'nn5_daily_with_missing', 'largest_2021', 'cmip6_1890', 'largest_2019', 'sunspot_with_missing', 'm5', 'elf', 'era5_1989', 'cmip6_1990', 'cockatoo', 'era5_2014', 'cmip6_1860', 'era5_1990', 'fred_md', 'cmip6_1910', 'monash_m3_other', 'era5_2007', 'cmip6_1955', 'subseasonal', 'traffic_hourly', 'monash_m3_monthly', 'cmip6_2010', 'era5_2009', 'wind_farms_with_missing', 'era5_2003', 'gfc14_load', 'project_tycho', 'bdg-2_bear', 'm1_monthly', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'australian_electricity_demand', 'm1_quarterly', 'pdb', 'lcl', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'largest_2017', 'tourism_monthly', 'HZMETRO', 'era5_2017', 'cmip6_1945', 'uber_tlc_daily', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'rideshare_with_missing', 'PEMS08', 'era5_2004', 'sceaux', 'solar_power', 'm1_yearly', 'bdg-2_fox', 'Q-TRAFFIC'], Term: long\n",
      "\n",
      "--- Domain Document ---\n",
      "Config 1 | Name: ['bull', 'gfc12_load', 'buildings_900k', 'london_smart_meters_with_missing', 'residential_pv_power', 'wind_power', 'elecdemand', 'spain', 'bdg-2_rat', 'bdg-2_panther', 'hog', 'smart', 'kdd2022', 'gfc17_load', 'borealis', 'ideal', 'residential_load_power', 'elf', 'cockatoo', 'wind_farms_with_missing', 'gfc14_load', 'bdg-2_bear', 'australian_electricity_demand', 'pdb', 'lcl', 'sceaux', 'solar_power', 'bdg-2_fox'], Term: short\n",
      "Config 2 | Name: ['bull', 'gfc12_load', 'buildings_900k', 'london_smart_meters_with_missing', 'residential_pv_power', 'wind_power', 'elecdemand', 'spain', 'bdg-2_rat', 'bdg-2_panther', 'hog', 'smart', 'kdd2022', 'gfc17_load', 'borealis', 'ideal', 'residential_load_power', 'elf', 'cockatoo', 'wind_farms_with_missing', 'gfc14_load', 'bdg-2_bear', 'australian_electricity_demand', 'pdb', 'lcl', 'sceaux', 'solar_power', 'bdg-2_fox'], Term: medium\n",
      "Config 3 | Name: ['bull', 'gfc12_load', 'buildings_900k', 'london_smart_meters_with_missing', 'residential_pv_power', 'wind_power', 'elecdemand', 'spain', 'bdg-2_rat', 'bdg-2_panther', 'hog', 'smart', 'kdd2022', 'gfc17_load', 'borealis', 'ideal', 'residential_load_power', 'elf', 'cockatoo', 'wind_farms_with_missing', 'gfc14_load', 'bdg-2_bear', 'australian_electricity_demand', 'pdb', 'lcl', 'sceaux', 'solar_power', 'bdg-2_fox'], Term: long\n",
      "Config 4 | Name: ['cmip6_1885', 'era5_1991', 'era5_2006', 'cmip6_1975', 'era5_2015', 'cmip6_1930', 'era5_2012', 'cmip6_1940', 'era5_2018', 'cmip6_1875', 'cmip6_1905', 'era5_2001', 'era5_1996', 'cmip6_1985', 'era5_1998', 'era5_1992', 'cmip6_1965', 'era5_2005', 'cmip6_1850', 'cmip6_1920', 'cmip6_1895', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'era5_2011', 'cmip6_1995', 'era5_2002', 'era5_2008', 'cmip6_1950', 'cmip6_1865', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'era5_2000', 'cmip6_1925', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'cmip6_1890', 'era5_1989', 'cmip6_1990', 'era5_2014', 'cmip6_1860', 'era5_1990', 'cmip6_1910', 'era5_2007', 'cmip6_1955', 'subseasonal', 'cmip6_2010', 'era5_2009', 'era5_2003', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'era5_2017', 'cmip6_1945', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'era5_2004'], Term: short\n",
      "Config 5 | Name: ['cmip6_1885', 'era5_1991', 'era5_2006', 'cmip6_1975', 'era5_2015', 'cmip6_1930', 'era5_2012', 'cmip6_1940', 'era5_2018', 'cmip6_1875', 'cmip6_1905', 'era5_2001', 'era5_1996', 'cmip6_1985', 'era5_1998', 'era5_1992', 'cmip6_1965', 'era5_2005', 'cmip6_1850', 'cmip6_1920', 'cmip6_1895', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'era5_2011', 'cmip6_1995', 'era5_2002', 'era5_2008', 'cmip6_1950', 'cmip6_1865', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'era5_2000', 'cmip6_1925', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'cmip6_1890', 'era5_1989', 'cmip6_1990', 'era5_2014', 'cmip6_1860', 'era5_1990', 'cmip6_1910', 'era5_2007', 'cmip6_1955', 'subseasonal', 'cmip6_2010', 'era5_2009', 'era5_2003', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'era5_2017', 'cmip6_1945', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'era5_2004'], Term: medium\n",
      "Config 6 | Name: ['cmip6_1885', 'era5_1991', 'era5_2006', 'cmip6_1975', 'era5_2015', 'cmip6_1930', 'era5_2012', 'cmip6_1940', 'era5_2018', 'cmip6_1875', 'cmip6_1905', 'era5_2001', 'era5_1996', 'cmip6_1985', 'era5_1998', 'era5_1992', 'cmip6_1965', 'era5_2005', 'cmip6_1850', 'cmip6_1920', 'cmip6_1895', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'era5_2011', 'cmip6_1995', 'era5_2002', 'era5_2008', 'cmip6_1950', 'cmip6_1865', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'era5_2000', 'cmip6_1925', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'cmip6_1890', 'era5_1989', 'cmip6_1990', 'era5_2014', 'cmip6_1860', 'era5_1990', 'cmip6_1910', 'era5_2007', 'cmip6_1955', 'subseasonal', 'cmip6_2010', 'era5_2009', 'era5_2003', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'era5_2017', 'cmip6_1945', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'era5_2004'], Term: long\n",
      "Config 7 | Name: ['SHMETRO', 'BEIJING_SUBWAY_30MIN', 'PEMS_BAY', 'covid_mobility', 'uber_tlc_hourly', 'largest_2020', 'traffic_weekly', 'largest_2018', 'PEMS07', 'PEMS03', 'covid19_energy', 'LOS_LOOP', 'taxi_30min', 'vehicle_trips_with_missing', 'pedestrian_counts', 'PEMS04', 'largest_2021', 'largest_2019', 'traffic_hourly', 'largest_2017', 'HZMETRO', 'uber_tlc_daily', 'rideshare_with_missing', 'PEMS08', 'Q-TRAFFIC'], Term: short\n",
      "Config 8 | Name: ['SHMETRO', 'BEIJING_SUBWAY_30MIN', 'PEMS_BAY', 'covid_mobility', 'uber_tlc_hourly', 'largest_2020', 'traffic_weekly', 'largest_2018', 'PEMS07', 'PEMS03', 'covid19_energy', 'LOS_LOOP', 'taxi_30min', 'vehicle_trips_with_missing', 'pedestrian_counts', 'PEMS04', 'largest_2021', 'largest_2019', 'traffic_hourly', 'largest_2017', 'HZMETRO', 'uber_tlc_daily', 'rideshare_with_missing', 'PEMS08', 'Q-TRAFFIC'], Term: medium\n",
      "Config 9 | Name: ['SHMETRO', 'BEIJING_SUBWAY_30MIN', 'PEMS_BAY', 'covid_mobility', 'uber_tlc_hourly', 'largest_2020', 'traffic_weekly', 'largest_2018', 'PEMS07', 'PEMS03', 'covid19_energy', 'LOS_LOOP', 'taxi_30min', 'vehicle_trips_with_missing', 'pedestrian_counts', 'PEMS04', 'largest_2021', 'largest_2019', 'traffic_hourly', 'largest_2017', 'HZMETRO', 'uber_tlc_daily', 'rideshare_with_missing', 'PEMS08', 'Q-TRAFFIC'], Term: long\n",
      "Config 10 | Name: ['wiki-rolling_nips', 'extended_web_traffic_with_missing', 'kaggle_web_traffic_weekly'], Term: short\n",
      "Config 11 | Name: ['wiki-rolling_nips', 'extended_web_traffic_with_missing', 'kaggle_web_traffic_weekly'], Term: medium\n",
      "Config 12 | Name: ['wiki-rolling_nips', 'extended_web_traffic_with_missing', 'kaggle_web_traffic_weekly'], Term: long\n",
      "Config 13 | Name: ['cdc_fluview_who_nrevss', 'cdc_fluview_ilinet', 'project_tycho'], Term: short\n",
      "Config 14 | Name: ['monash_m3_quarterly', 'tourism_yearly', 'cif_2016_6', 'monash_m3_yearly', 'bitcoin_with_missing', 'tourism_quarterly', 'cif_2016_12', 'godaddy', 'nn5_weekly', 'nn5_daily_with_missing', 'fred_md', 'monash_m3_other', 'monash_m3_monthly', 'm1_monthly', 'm1_quarterly', 'tourism_monthly', 'm1_yearly'], Term: short\n",
      "Config 15 | Name: ['alibaba_cluster_trace_2018', 'borg_cluster_data_2011', 'azure_vm_traces_2017'], Term: short\n",
      "Config 16 | Name: ['alibaba_cluster_trace_2018', 'borg_cluster_data_2011', 'azure_vm_traces_2017'], Term: medium\n",
      "Config 17 | Name: ['alibaba_cluster_trace_2018', 'borg_cluster_data_2011', 'azure_vm_traces_2017'], Term: long\n",
      "Config 18 | Name: ['favorita_sales', 'favorita_transactions', 'm5'], Term: short\n",
      "Config 19 | Name: ['beijing_air_quality', 'china_air_quality', 'sunspot_with_missing'], Term: short\n",
      "Config 20 | Name: ['beijing_air_quality', 'china_air_quality', 'sunspot_with_missing'], Term: medium\n",
      "Config 21 | Name: ['beijing_air_quality', 'china_air_quality', 'sunspot_with_missing'], Term: long\n",
      "Config 22 | Name: ['wiki-rolling_nips', 'alibaba_cluster_trace_2018', 'borg_cluster_data_2011', 'extended_web_traffic_with_missing', 'azure_vm_traces_2017', 'kaggle_web_traffic_weekly'], Term: short\n",
      "Config 23 | Name: ['wiki-rolling_nips', 'alibaba_cluster_trace_2018', 'borg_cluster_data_2011', 'extended_web_traffic_with_missing', 'azure_vm_traces_2017', 'kaggle_web_traffic_weekly'], Term: medium\n",
      "Config 24 | Name: ['wiki-rolling_nips', 'alibaba_cluster_trace_2018', 'borg_cluster_data_2011', 'extended_web_traffic_with_missing', 'azure_vm_traces_2017', 'kaggle_web_traffic_weekly'], Term: long\n",
      "Config 25 | Name: ['cmip6_1885', 'era5_1991', 'era5_2006', 'cmip6_1975', 'era5_2015', 'cmip6_1930', 'era5_2012', 'cmip6_1940', 'era5_2018', 'cmip6_1875', 'cmip6_1905', 'era5_2001', 'era5_1996', 'cmip6_1985', 'era5_1998', 'era5_1992', 'cmip6_1965', 'era5_2005', 'cmip6_1850', 'cmip6_1920', 'cmip6_1895', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'era5_2011', 'cmip6_1995', 'era5_2002', 'era5_2008', 'cmip6_1950', 'cmip6_1865', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'beijing_air_quality', 'era5_2000', 'cmip6_1925', 'china_air_quality', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'cmip6_1890', 'sunspot_with_missing', 'era5_1989', 'cmip6_1990', 'era5_2014', 'cmip6_1860', 'era5_1990', 'cmip6_1910', 'era5_2007', 'cmip6_1955', 'subseasonal', 'cmip6_2010', 'era5_2009', 'era5_2003', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'era5_2017', 'cmip6_1945', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'era5_2004'], Term: short\n",
      "Config 26 | Name: ['cmip6_1885', 'era5_1991', 'era5_2006', 'cmip6_1975', 'era5_2015', 'cmip6_1930', 'era5_2012', 'cmip6_1940', 'era5_2018', 'cmip6_1875', 'cmip6_1905', 'era5_2001', 'era5_1996', 'cmip6_1985', 'era5_1998', 'era5_1992', 'cmip6_1965', 'era5_2005', 'cmip6_1850', 'cmip6_1920', 'cmip6_1895', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'era5_2011', 'cmip6_1995', 'era5_2002', 'era5_2008', 'cmip6_1950', 'cmip6_1865', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'beijing_air_quality', 'era5_2000', 'cmip6_1925', 'china_air_quality', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'cmip6_1890', 'sunspot_with_missing', 'era5_1989', 'cmip6_1990', 'era5_2014', 'cmip6_1860', 'era5_1990', 'cmip6_1910', 'era5_2007', 'cmip6_1955', 'subseasonal', 'cmip6_2010', 'era5_2009', 'era5_2003', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'era5_2017', 'cmip6_1945', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'era5_2004'], Term: medium\n",
      "Config 27 | Name: ['cmip6_1885', 'era5_1991', 'era5_2006', 'cmip6_1975', 'era5_2015', 'cmip6_1930', 'era5_2012', 'cmip6_1940', 'era5_2018', 'cmip6_1875', 'cmip6_1905', 'era5_2001', 'era5_1996', 'cmip6_1985', 'era5_1998', 'era5_1992', 'cmip6_1965', 'era5_2005', 'cmip6_1850', 'cmip6_1920', 'cmip6_1895', 'subseasonal_precip', 'cmip6_2005', 'era5_2016', 'era5_2011', 'cmip6_1995', 'era5_2002', 'era5_2008', 'cmip6_1950', 'cmip6_1865', 'era5_1995', 'cmip6_1915', 'cmip6_1855', 'beijing_air_quality', 'era5_2000', 'cmip6_1925', 'china_air_quality', 'era5_1997', 'cmip6_1960', 'cmip6_2000', 'era5_2013', 'cmip6_1890', 'sunspot_with_missing', 'era5_1989', 'cmip6_1990', 'era5_2014', 'cmip6_1860', 'era5_1990', 'cmip6_1910', 'era5_2007', 'cmip6_1955', 'subseasonal', 'cmip6_2010', 'era5_2009', 'era5_2003', 'cmip6_1880', 'era5_1994', 'era5_2010', 'cmip6_1935', 'cmip6_1970', 'oikolab_weather', 'cmip6_1870', 'cmip6_1900', 'era5_2017', 'cmip6_1945', 'era5_1993', 'era5_1999', 'cmip6_1980', 'weather', 'era5_2004'], Term: long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(yaml_path, \"r\") as file:\n",
    "    documents = list(yaml.load_all(file, Loader=yaml.SafeLoader))\n",
    "\n",
    "num_documents = len(documents)\n",
    "print(f\"Number of documents loaded: {num_documents}\\n\")\n",
    "\n",
    "general_document, domain_document = documents[0], documents[1]\n",
    "\n",
    "print(\"--- General Document ---\")\n",
    "for i, config in enumerate(general_document):\n",
    "    names = config[\"names\"]\n",
    "    term = config[\"term\"]\n",
    "    print(f\"Config {i + 1} | Name: {names}, Term: {term}\")\n",
    "print()\n",
    "\n",
    "print(\"--- Domain Document ---\")\n",
    "for i, config in enumerate(domain_document):\n",
    "    names = config[\"names\"]\n",
    "    term = config[\"term\"]\n",
    "    print(f\"Config {i + 1} | Name: {names}, Term: {term}\")\n",
    "print()\n",
    "\n",
    "assert len(general_document) + len(domain_document) == 3 + 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train-test split's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train_test datasets: 97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_series</th>\n",
       "      <th>target_dim</th>\n",
       "      <th>_min_series_length</th>\n",
       "      <th>sum_series_length</th>\n",
       "      <th>prediction_length</th>\n",
       "      <th>windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOOP_SEATTLE/5T</td>\n",
       "      <td>short</td>\n",
       "      <td>5T</td>\n",
       "      <td>Transport</td>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>105120</td>\n",
       "      <td>33953760</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOOP_SEATTLE/D</td>\n",
       "      <td>short</td>\n",
       "      <td>D</td>\n",
       "      <td>Transport</td>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>117895</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOOP_SEATTLE/H</td>\n",
       "      <td>short</td>\n",
       "      <td>H</td>\n",
       "      <td>Transport</td>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>8760</td>\n",
       "      <td>2829480</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M_DENSE/D</td>\n",
       "      <td>short</td>\n",
       "      <td>D</td>\n",
       "      <td>Transport</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>21900</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M_DENSE/H</td>\n",
       "      <td>short</td>\n",
       "      <td>H</td>\n",
       "      <td>Transport</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>17520</td>\n",
       "      <td>525600</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name   term freq     domain  num_series  target_dim   \n",
       "0  LOOP_SEATTLE/5T  short   5T  Transport         323           1  \\\n",
       "1   LOOP_SEATTLE/D  short    D  Transport         323           1   \n",
       "2   LOOP_SEATTLE/H  short    H  Transport         323           1   \n",
       "3        M_DENSE/D  short    D  Transport          30           1   \n",
       "4        M_DENSE/H  short    H  Transport          30           1   \n",
       "\n",
       "   _min_series_length  sum_series_length  prediction_length  windows  \n",
       "0              105120           33953760                 48       20  \n",
       "1                 365             117895                 30        2  \n",
       "2                8760            2829480                 48       19  \n",
       "3                 730              21900                 30        3  \n",
       "4               17520             525600                 48       20  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = SplitType.TRAIN_TEST\n",
    "metadata_path = Path(\"resources\") / split / \"metadata.csv\"\n",
    "\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Total number of {split} datasets: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View all of the unique forecasting terms and count the number of datasets that belong to each term. Each forecasting term multiplies the original prediciton length by a given multipler:\n",
    "- \"long\" multiplies the original prediction length by 15\n",
    "- \"medium\" multiplies the original prediction length by 10  \n",
    "- \"short\" multiplies the original prediction length by 1 (no change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique terms: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>long</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     term  count\n",
       "0   short     55\n",
       "1    long     21\n",
       "2  medium     21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "term_counts = get_count_df(df, columns=[\"term\"], ascending=False)\n",
    "\n",
    "print(f\"Number of unique terms: {len(term_counts)}\")\n",
    "display(term_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each term and its associated dataset names to a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of general configurations: 3\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "general_document = []\n",
    "\n",
    "for term in terms:\n",
    "    names = df[df[\"term\"] == term][\"name\"].tolist()\n",
    "\n",
    "    # Add a mapping for each term\n",
    "    general_document.append(\n",
    "        {\n",
    "            \"term\": term,\n",
    "            \"names\": names,\n",
    "        }\n",
    "    )\n",
    "\n",
    "documents = [general_document]\n",
    "\n",
    "num_general_configs = len(general_document)\n",
    "\n",
    "yaml_path = Path(\"configs\") / split_type / \"datasets.yaml\"\n",
    "\n",
    "print(f\"Number of general configurations: {num_general_configs}\")\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump_all(documents, file, explicit_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the YAML file to ensure the configurations were saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 1\n",
      "--- Document 1 ---\n",
      "- names:\n",
      "  - LOOP_SEATTLE/5T\n",
      "  - LOOP_SEATTLE/D\n",
      "  - LOOP_SEATTLE/H\n",
      "  - M_DENSE/D\n",
      "  - M_DENSE/H\n",
      "  - SZ_TAXI/15T\n",
      "  - SZ_TAXI/H\n",
      "  - bitbrains_fast_storage/5T\n",
      "  - bitbrains_fast_storage/H\n",
      "  - bitbrains_rnd/5T\n",
      "  - bitbrains_rnd/H\n",
      "  - bizitobs_application\n",
      "  - bizitobs_l2c/5T\n",
      "  - bizitobs_l2c/H\n",
      "  - bizitobs_service\n",
      "  - car_parts_with_missing\n",
      "  - covid_deaths\n",
      "  - electricity/15T\n",
      "  - electricity/D\n",
      "  - electricity/H\n",
      "  - electricity/W\n",
      "  - ett1/15T\n",
      "  - ett1/D\n",
      "  - ett1/H\n",
      "  - ett1/W\n",
      "  - ett2/15T\n",
      "  - ett2/D\n",
      "  - ett2/H\n",
      "  - ett2/W\n",
      "  - hierarchical_sales/D\n",
      "  - hierarchical_sales/W\n",
      "  - hospital\n",
      "  - jena_weather/10T\n",
      "  - jena_weather/D\n",
      "  - jena_weather/H\n",
      "  - kdd_cup_2018_with_missing/D\n",
      "  - kdd_cup_2018_with_missing/H\n",
      "  - m4_daily\n",
      "  - m4_hourly\n",
      "  - m4_monthly\n",
      "  - m4_quarterly\n",
      "  - m4_weekly\n",
      "  - m4_yearly\n",
      "  - restaurant\n",
      "  - saugeenday/D\n",
      "  - saugeenday/M\n",
      "  - saugeenday/W\n",
      "  - solar/10T\n",
      "  - solar/D\n",
      "  - solar/H\n",
      "  - solar/W\n",
      "  - temperature_rain_with_missing\n",
      "  - us_births/D\n",
      "  - us_births/M\n",
      "  - us_births/W\n",
      "  term: short\n",
      "- names:\n",
      "  - LOOP_SEATTLE/5T\n",
      "  - LOOP_SEATTLE/H\n",
      "  - M_DENSE/H\n",
      "  - SZ_TAXI/15T\n",
      "  - bitbrains_fast_storage/5T\n",
      "  - bitbrains_rnd/5T\n",
      "  - bizitobs_application\n",
      "  - bizitobs_l2c/5T\n",
      "  - bizitobs_l2c/H\n",
      "  - bizitobs_service\n",
      "  - electricity/15T\n",
      "  - electricity/H\n",
      "  - ett1/15T\n",
      "  - ett1/H\n",
      "  - ett2/15T\n",
      "  - ett2/H\n",
      "  - jena_weather/10T\n",
      "  - jena_weather/H\n",
      "  - kdd_cup_2018_with_missing/H\n",
      "  - solar/10T\n",
      "  - solar/H\n",
      "  term: medium\n",
      "- names:\n",
      "  - LOOP_SEATTLE/5T\n",
      "  - LOOP_SEATTLE/H\n",
      "  - M_DENSE/H\n",
      "  - SZ_TAXI/15T\n",
      "  - bitbrains_fast_storage/5T\n",
      "  - bitbrains_rnd/5T\n",
      "  - bizitobs_application\n",
      "  - bizitobs_l2c/5T\n",
      "  - bizitobs_l2c/H\n",
      "  - bizitobs_service\n",
      "  - electricity/15T\n",
      "  - electricity/H\n",
      "  - ett1/15T\n",
      "  - ett1/H\n",
      "  - ett2/15T\n",
      "  - ett2/H\n",
      "  - jena_weather/10T\n",
      "  - jena_weather/H\n",
      "  - kdd_cup_2018_with_missing/H\n",
      "  - solar/10T\n",
      "  - solar/H\n",
      "  term: long\n",
      "\n",
      "Config 1:\n",
      "  Term: short\n",
      "  Number of names: 55\n",
      "  Names: LOOP_SEATTLE/5T, LOOP_SEATTLE/D, LOOP_SEATTLE/H, M_DENSE/D, M_DENSE/H, SZ_TAXI/15T, SZ_TAXI/H, bitbrains_fast_storage/5T, bitbrains_fast_storage/H, bitbrains_rnd/5T, bitbrains_rnd/H, bizitobs_application, bizitobs_l2c/5T, bizitobs_l2c/H, bizitobs_service, car_parts_with_missing, covid_deaths, electricity/15T, electricity/D, electricity/H, electricity/W, ett1/15T, ett1/D, ett1/H, ett1/W, ett2/15T, ett2/D, ett2/H, ett2/W, hierarchical_sales/D, hierarchical_sales/W, hospital, jena_weather/10T, jena_weather/D, jena_weather/H, kdd_cup_2018_with_missing/D, kdd_cup_2018_with_missing/H, m4_daily, m4_hourly, m4_monthly, m4_quarterly, m4_weekly, m4_yearly, restaurant, saugeenday/D, saugeenday/M, saugeenday/W, solar/10T, solar/D, solar/H, solar/W, temperature_rain_with_missing, us_births/D, us_births/M, us_births/W\n",
      "\n",
      "Config 2:\n",
      "  Term: medium\n",
      "  Number of names: 21\n",
      "  Names: LOOP_SEATTLE/5T, LOOP_SEATTLE/H, M_DENSE/H, SZ_TAXI/15T, bitbrains_fast_storage/5T, bitbrains_rnd/5T, bizitobs_application, bizitobs_l2c/5T, bizitobs_l2c/H, bizitobs_service, electricity/15T, electricity/H, ett1/15T, ett1/H, ett2/15T, ett2/H, jena_weather/10T, jena_weather/H, kdd_cup_2018_with_missing/H, solar/10T, solar/H\n",
      "\n",
      "Config 3:\n",
      "  Term: long\n",
      "  Number of names: 21\n",
      "  Names: LOOP_SEATTLE/5T, LOOP_SEATTLE/H, M_DENSE/H, SZ_TAXI/15T, bitbrains_fast_storage/5T, bitbrains_rnd/5T, bizitobs_application, bizitobs_l2c/5T, bizitobs_l2c/H, bizitobs_service, electricity/15T, electricity/H, ett1/15T, ett1/H, ett2/15T, ett2/H, jena_weather/10T, jena_weather/H, kdd_cup_2018_with_missing/H, solar/10T, solar/H\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(yaml_path, \"r\") as file:\n",
    "    documents = list(yaml.load_all(file, Loader=yaml.SafeLoader))\n",
    "\n",
    "num_documents = len(documents)\n",
    "print(f\"Number of documents loaded: {num_documents}\")\n",
    "\n",
    "for i, document in enumerate(documents, 1):\n",
    "    print(f\"--- Document {i} ---\")\n",
    "    print(yaml.dump(document, sort_keys=False))\n",
    "\n",
    "# Access the general configurations\n",
    "general_configs = documents[0]\n",
    "\n",
    "assert len(general_configs) == 3\n",
    "\n",
    "for i, config in enumerate(general_configs):\n",
    "    print(f\"Config {i+1}:\")\n",
    "\n",
    "    term = config[\"term\"]\n",
    "    print(f\"  Term: {term}\")\n",
    "\n",
    "    num_names = len(config[\"names\"])\n",
    "    term_mask = term_counts[\"term\"] == term\n",
    "    assert num_names == term_counts.loc[term_mask, \"count\"].iloc[0]\n",
    "\n",
    "    print(f\"  Number of names: {num_names}\")\n",
    "    print(f\"  Names: {', '.join(config['names'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain-Specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View all of the unique domain-term combinations and count the number of datasets that belong to each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domains: Transport, Web/CloudOps, Sales, Healthcare, Energy, Nature, Econ/Fin\n",
      "Terms: short, medium, long\n",
      "Number of unique domain-term combinations: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>short</th>\n",
       "      <th>medium</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Econ/Fin</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Healthcare</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sales</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transport</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain  short  medium  long\n",
       "0      Econ/Fin    6.0     NaN   NaN\n",
       "1        Energy   16.0     8.0   8.0\n",
       "2    Healthcare    5.0     NaN   NaN\n",
       "3        Nature    9.0     3.0   3.0\n",
       "4         Sales    4.0     NaN   NaN\n",
       "5     Transport    7.0     4.0   4.0\n",
       "6  Web/CloudOps    8.0     6.0   6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domains, terms = df[\"domain\"].unique(), df[\"term\"].unique()\n",
    "\n",
    "domain_term_counts = get_count_df(\n",
    "    df,\n",
    "    columns=[\"domain\", \"term\"],\n",
    "    ascending=False,\n",
    ")\n",
    "\n",
    "# Convert each term into its own column\n",
    "pivoted_df = domain_term_counts.pivot(\n",
    "    index=\"domain\",\n",
    "    columns=\"term\",\n",
    "    values=\"count\",\n",
    ").reset_index()\n",
    "\n",
    "# Remove old \"term\" column\n",
    "pivoted_df.columns.name = None\n",
    "\n",
    "# Reorder columns\n",
    "pivoted_df = pivoted_df[\n",
    "    [\n",
    "        \"domain\",\n",
    "        \"short\",\n",
    "        \"medium\",\n",
    "        \"long\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(f'Domains: {\", \".join(domains)}')\n",
    "print(f'Terms: {\", \".join(terms)}')\n",
    "print(f\"Number of unique domain-term combinations: {len(domain_term_counts)}\")\n",
    "display(pivoted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add each domain-term combination's domain, term, and dataset names to the yaml file.\n",
    "- We'll only create short groups for the following domains because they don't have any medium or long datasets in the train-test split:\n",
    "  - Econ/Fin\n",
    "  - Healthcare\n",
    "  - Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 'medium' for 'Sales'...\n",
      "Skipping 'long' for 'Sales'...\n",
      "Skipping 'medium' for 'Healthcare'...\n",
      "Skipping 'long' for 'Healthcare'...\n",
      "Skipping 'medium' for 'Econ/Fin'...\n",
      "Skipping 'long' for 'Econ/Fin'...\n",
      "No datasets found for domain 'Econ/Fin' and term 'short'\n",
      "No datasets found for domain 'Econ/Fin' and term 'medium'\n",
      "No datasets found for domain 'Econ/Fin' and term 'long'\n",
      "Number of domain configs: 18\n"
     ]
    }
   ],
   "source": [
    "from utils import Domain\n",
    "\n",
    "excluded_domains = [\n",
    "    \"Econ/Fin\",\n",
    "    \"Healthcare\",\n",
    "    \"Sales\",\n",
    "]\n",
    "\n",
    "domain_document = []\n",
    "\n",
    "for domain in domains:\n",
    "\n",
    "    for term in terms:\n",
    "        # Exclude domains that only have short term datasets\n",
    "        if domain in excluded_domains and term != \"short\":\n",
    "            print(f\"Skipping '{term}' for '{domain}'...\")\n",
    "            continue\n",
    "\n",
    "        domain_mask, term_mask = df[\"domain\"] == domain, df[\"term\"] == term\n",
    "        filtered_df = df[domain_mask & term_mask]\n",
    "\n",
    "        names = filtered_df[\"name\"].tolist()\n",
    "\n",
    "        if not names:\n",
    "            print(f\"No datasets found for domain '{domain}' and term '{term}'\")\n",
    "            continue\n",
    "\n",
    "        # Add a mapping for each domain-term combination\n",
    "        domain_document.append(\n",
    "            {\n",
    "                \"domain\": domain,\n",
    "                \"term\": term,\n",
    "                \"names\": names,\n",
    "            }\n",
    "        )\n",
    "\n",
    "domain_pairs = [\n",
    "    (Domain.WEB, Domain.CLOUDOPS),\n",
    "    (Domain.NATURE, Domain.CLIMATE),\n",
    "]\n",
    "\n",
    "# Add custom domain pairs\n",
    "for domain_pair in domain_pairs:\n",
    "    num_short, num_medium, num_long = (0,) * 3\n",
    "    for term in terms:\n",
    "        domain_1, domain_2 = domain_pair\n",
    "        domain_mask = df[\"domain\"].isin([domain_1, domain_2])\n",
    "        term_mask = df[\"term\"] == term\n",
    "\n",
    "        filtered_df = df[domain_mask & term_mask]\n",
    "        names = filtered_df[\"name\"].tolist()\n",
    "\n",
    "        if not names:\n",
    "            print(f\"No datasets found for domain '{domain}' and term '{term}'\")\n",
    "            continue\n",
    "\n",
    "        if term == \"short\":\n",
    "            num_short = len(names)\n",
    "        elif term == \"medium\":\n",
    "            num_medium = len(names)\n",
    "        else:\n",
    "            num_long = len(names)\n",
    "\n",
    "        # Add a mapping for each domain-term combination\n",
    "        domain_document.append(\n",
    "            {\n",
    "                \"domain\": f\"{domain_1},{domain_2}\",\n",
    "                \"term\": term,\n",
    "                \"names\": names,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    new_row = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"domain\": f\"{domain_1},{domain_2}\",\n",
    "                \"short\": num_short,\n",
    "                \"medium\": num_medium,\n",
    "                \"long\": num_long,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pivoted_df = pd.concat([pivoted_df, new_row], ignore_index=True)\n",
    "\n",
    "documents.append(domain_document)\n",
    "num_domain_configs = len(domain_document)\n",
    "print(f\"Number of domain configs: {num_domain_configs}\")\n",
    "\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump_all(\n",
    "        documents,\n",
    "        file,\n",
    "        explicit_start=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the YAML file to ensure the configurations were saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 2\n",
      "\n",
      "--- General Document ---\n",
      "Config 1 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/D', 'LOOP_SEATTLE/H', 'M_DENSE/D', 'M_DENSE/H', 'SZ_TAXI/15T', 'SZ_TAXI/H', 'bitbrains_fast_storage/5T', 'bitbrains_fast_storage/H', 'bitbrains_rnd/5T', 'bitbrains_rnd/H', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service', 'car_parts_with_missing', 'covid_deaths', 'electricity/15T', 'electricity/D', 'electricity/H', 'electricity/W', 'ett1/15T', 'ett1/D', 'ett1/H', 'ett1/W', 'ett2/15T', 'ett2/D', 'ett2/H', 'ett2/W', 'hierarchical_sales/D', 'hierarchical_sales/W', 'hospital', 'jena_weather/10T', 'jena_weather/D', 'jena_weather/H', 'kdd_cup_2018_with_missing/D', 'kdd_cup_2018_with_missing/H', 'm4_daily', 'm4_hourly', 'm4_monthly', 'm4_quarterly', 'm4_weekly', 'm4_yearly', 'restaurant', 'saugeenday/D', 'saugeenday/M', 'saugeenday/W', 'solar/10T', 'solar/D', 'solar/H', 'solar/W', 'temperature_rain_with_missing', 'us_births/D', 'us_births/M', 'us_births/W'], Term: short\n",
      "Config 2 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T', 'bitbrains_fast_storage/5T', 'bitbrains_rnd/5T', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service', 'electricity/15T', 'electricity/H', 'ett1/15T', 'ett1/H', 'ett2/15T', 'ett2/H', 'jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H', 'solar/10T', 'solar/H'], Term: medium\n",
      "Config 3 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T', 'bitbrains_fast_storage/5T', 'bitbrains_rnd/5T', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service', 'electricity/15T', 'electricity/H', 'ett1/15T', 'ett1/H', 'ett2/15T', 'ett2/H', 'jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H', 'solar/10T', 'solar/H'], Term: long\n",
      "\n",
      "--- Domain Document ---\n",
      "Config 1 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/D', 'LOOP_SEATTLE/H', 'M_DENSE/D', 'M_DENSE/H', 'SZ_TAXI/15T', 'SZ_TAXI/H'], Term: short\n",
      "Config 2 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T'], Term: medium\n",
      "Config 3 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T'], Term: long\n",
      "Config 4 | Name: ['bitbrains_fast_storage/5T', 'bitbrains_fast_storage/H', 'bitbrains_rnd/5T', 'bitbrains_rnd/H', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service'], Term: short\n",
      "Config 5 | Name: ['bitbrains_fast_storage/5T', 'bitbrains_rnd/5T', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service'], Term: medium\n",
      "Config 6 | Name: ['bitbrains_fast_storage/5T', 'bitbrains_rnd/5T', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service'], Term: long\n",
      "Config 7 | Name: ['car_parts_with_missing', 'hierarchical_sales/D', 'hierarchical_sales/W', 'restaurant'], Term: short\n",
      "Config 8 | Name: ['covid_deaths', 'hospital', 'us_births/D', 'us_births/M', 'us_births/W'], Term: short\n",
      "Config 9 | Name: ['electricity/15T', 'electricity/D', 'electricity/H', 'electricity/W', 'ett1/15T', 'ett1/D', 'ett1/H', 'ett1/W', 'ett2/15T', 'ett2/D', 'ett2/H', 'ett2/W', 'solar/10T', 'solar/D', 'solar/H', 'solar/W'], Term: short\n",
      "Config 10 | Name: ['electricity/15T', 'electricity/H', 'ett1/15T', 'ett1/H', 'ett2/15T', 'ett2/H', 'solar/10T', 'solar/H'], Term: medium\n",
      "Config 11 | Name: ['electricity/15T', 'electricity/H', 'ett1/15T', 'ett1/H', 'ett2/15T', 'ett2/H', 'solar/10T', 'solar/H'], Term: long\n",
      "Config 12 | Name: ['jena_weather/10T', 'jena_weather/D', 'jena_weather/H', 'kdd_cup_2018_with_missing/D', 'kdd_cup_2018_with_missing/H', 'saugeenday/D', 'saugeenday/M', 'saugeenday/W', 'temperature_rain_with_missing'], Term: short\n",
      "Config 13 | Name: ['jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H'], Term: medium\n",
      "Config 14 | Name: ['jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H'], Term: long\n",
      "Config 15 | Name: ['m4_daily', 'm4_hourly', 'm4_monthly', 'm4_quarterly', 'm4_weekly', 'm4_yearly'], Term: short\n",
      "Config 16 | Name: ['jena_weather/10T', 'jena_weather/D', 'jena_weather/H', 'kdd_cup_2018_with_missing/D', 'kdd_cup_2018_with_missing/H', 'saugeenday/D', 'saugeenday/M', 'saugeenday/W', 'temperature_rain_with_missing'], Term: short\n",
      "Config 17 | Name: ['jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H'], Term: medium\n",
      "Config 18 | Name: ['jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H'], Term: long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(yaml_path, \"r\") as file:\n",
    "    documents = list(yaml.load_all(file, Loader=yaml.SafeLoader))\n",
    "\n",
    "num_documents = len(documents)\n",
    "print(f\"Number of documents loaded: {num_documents}\\n\")\n",
    "\n",
    "general_document, domain_document = documents[0], documents[1]\n",
    "\n",
    "print(\"--- General Document ---\")\n",
    "for i, config in enumerate(general_document):\n",
    "    names = config[\"names\"]\n",
    "    term = config[\"term\"]\n",
    "    print(f\"Config {i + 1} | Name: {names}, Term: {term}\")\n",
    "print()\n",
    "\n",
    "print(\"--- Domain Document ---\")\n",
    "for i, config in enumerate(domain_document):\n",
    "    names = config[\"names\"]\n",
    "    term = config[\"term\"]\n",
    "    print(f\"Config {i + 1} | Name: {names}, Term: {term}\")\n",
    "print()\n",
    "\n",
    "assert len(general_document) + len(domain_document) == 3 + 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset-Specific "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some of the dataset name-term combinations. For the sake of brevity, we'll only display a few of the dataset name-term combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique name-term pairs: 97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOOP_SEATTLE/5T</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOOP_SEATTLE/D</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOOP_SEATTLE/H</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M_DENSE/D</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M_DENSE/H</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name   term\n",
       "0  LOOP_SEATTLE/5T  short\n",
       "1   LOOP_SEATTLE/D  short\n",
       "2   LOOP_SEATTLE/H  short\n",
       "3        M_DENSE/D  short\n",
       "4        M_DENSE/H  short"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_term_combinations = df[[\"name\", \"term\"]]\n",
    "\n",
    "print(f\"Number of unique name-term pairs: {len(name_term_combinations)}\")\n",
    "name_term_combinations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add each unique name-term combination to our YAML data and save the resulting YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dataset-specific configurations: 97\n"
     ]
    }
   ],
   "source": [
    "dataset_document = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Add a mapping for each name-term combination\n",
    "    dataset_document.append(\n",
    "        {\n",
    "            \"term\": row[\"term\"],\n",
    "            \"names\": [row[\"name\"]],\n",
    "        }\n",
    "    )\n",
    "\n",
    "documents.append(dataset_document)\n",
    "\n",
    "num_dataset_specific_configs = len(dataset_document)\n",
    "print(f\"Number of dataset-specific configurations: {num_dataset_specific_configs}\")\n",
    "\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump_all(\n",
    "        documents,\n",
    "        file,\n",
    "        explicit_start=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the YAML file to ensure the configurations were saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 3\n",
      "\n",
      "--- General Document ---\n",
      "Config 1 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/D', 'LOOP_SEATTLE/H', 'M_DENSE/D', 'M_DENSE/H', 'SZ_TAXI/15T', 'SZ_TAXI/H', 'bitbrains_fast_storage/5T', 'bitbrains_fast_storage/H', 'bitbrains_rnd/5T', 'bitbrains_rnd/H', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service', 'car_parts_with_missing', 'covid_deaths', 'electricity/15T', 'electricity/D', 'electricity/H', 'electricity/W', 'ett1/15T', 'ett1/D', 'ett1/H', 'ett1/W', 'ett2/15T', 'ett2/D', 'ett2/H', 'ett2/W', 'hierarchical_sales/D', 'hierarchical_sales/W', 'hospital', 'jena_weather/10T', 'jena_weather/D', 'jena_weather/H', 'kdd_cup_2018_with_missing/D', 'kdd_cup_2018_with_missing/H', 'm4_daily', 'm4_hourly', 'm4_monthly', 'm4_quarterly', 'm4_weekly', 'm4_yearly', 'restaurant', 'saugeenday/D', 'saugeenday/M', 'saugeenday/W', 'solar/10T', 'solar/D', 'solar/H', 'solar/W', 'temperature_rain_with_missing', 'us_births/D', 'us_births/M', 'us_births/W'], Term: short\n",
      "Config 2 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T', 'bitbrains_fast_storage/5T', 'bitbrains_rnd/5T', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service', 'electricity/15T', 'electricity/H', 'ett1/15T', 'ett1/H', 'ett2/15T', 'ett2/H', 'jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H', 'solar/10T', 'solar/H'], Term: medium\n",
      "Config 3 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T', 'bitbrains_fast_storage/5T', 'bitbrains_rnd/5T', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service', 'electricity/15T', 'electricity/H', 'ett1/15T', 'ett1/H', 'ett2/15T', 'ett2/H', 'jena_weather/10T', 'jena_weather/H', 'kdd_cup_2018_with_missing/H', 'solar/10T', 'solar/H'], Term: long\n",
      "\n",
      "--- Domain Document ---\n",
      "Config 1 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/D', 'LOOP_SEATTLE/H', 'M_DENSE/D', 'M_DENSE/H', 'SZ_TAXI/15T', 'SZ_TAXI/H'], Term: short\n",
      "Config 2 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T'], Term: medium\n",
      "Config 3 | Name: ['LOOP_SEATTLE/5T', 'LOOP_SEATTLE/H', 'M_DENSE/H', 'SZ_TAXI/15T'], Term: long\n",
      "Config 4 | Name: ['bitbrains_fast_storage/5T', 'bitbrains_fast_storage/H', 'bitbrains_rnd/5T', 'bitbrains_rnd/H', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service'], Term: short\n",
      "Config 5 | Name: ['bitbrains_fast_storage/5T', 'bitbrains_rnd/5T', 'bizitobs_application', 'bizitobs_l2c/5T', 'bizitobs_l2c/H', 'bizitobs_service'], Term: medium\n",
      "\n",
      "--- Dataset Level Document ---\n",
      "Config 1 | Name: ['LOOP_SEATTLE/5T'], Term: short\n",
      "Config 2 | Name: ['LOOP_SEATTLE/D'], Term: short\n",
      "Config 3 | Name: ['LOOP_SEATTLE/H'], Term: short\n",
      "Config 4 | Name: ['M_DENSE/D'], Term: short\n",
      "Config 5 | Name: ['M_DENSE/H'], Term: short\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(yaml_path, \"r\") as file:\n",
    "    documents = list(yaml.load_all(file, Loader=yaml.SafeLoader))\n",
    "\n",
    "num_documents = len(documents)\n",
    "print(f\"Number of documents loaded: {num_documents}\\n\")\n",
    "assert len(documents) == 3\n",
    "\n",
    "general_document, domain_document, dataset_document = documents\n",
    "\n",
    "print(\"--- General Document ---\")\n",
    "for i, config in enumerate(general_document[:5]):\n",
    "    names = config[\"names\"]\n",
    "    term = config[\"term\"]\n",
    "    print(f\"Config {i + 1} | Name: {names}, Term: {term}\")\n",
    "print()\n",
    "\n",
    "print(\"--- Domain Document ---\")\n",
    "for i, config in enumerate(domain_document[:5]):\n",
    "    names = config[\"names\"]\n",
    "    term = config[\"term\"]\n",
    "    print(f\"Config {i + 1} | Name: {names}, Term: {term}\")\n",
    "print()\n",
    "\n",
    "print(\"--- Dataset Level Document ---\")\n",
    "for i, config in enumerate(dataset_document[:5]):\n",
    "    names = config[\"names\"]\n",
    "    term = config[\"term\"]\n",
    "    print(f\"Config {i + 1} | Name: {names}, Term: {term}\")\n",
    "print()\n",
    "\n",
    "assert (\n",
    "    len(general_document) + len(domain_document) + len(dataset_document) == 3 + 18 + 97\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
