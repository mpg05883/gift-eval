{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Running Chronos and Chronos-Bolt models on gift-eval benchmark\n",
    "\n",
    "This notebook shows how to run Chronos and Chronos-Bolt models on the gift-eval benchmark.\n",
    "\n",
    "Make sure you download the gift-eval benchmark and set the `GIFT-EVAL` environment variable correctly before running this notebook.\n",
    "\n",
    "We will use the `Dataset` class to load the data and run the model. If you have not already please check out the [dataset.ipynb](./dataset.ipynb) notebook to learn more about the `Dataset` class. We are going to just run the model on two datasets for brevity. But feel free to run on any dataset by changing the `short_datasets` and `med_long_datasets` variables below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Chronos package:\n",
    "``\n",
    "pip install chronos-forecasting\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "split_name = \"train_test\"\n",
    "info_path = Path(\"resources\") / split_name / \"info.csv\"\n",
    "\n",
    "df = pd.read_csv(info_path)\n",
    "\n",
    "prop_path = Path(\"notebooks\") / \"dataset_properties.json\"\n",
    "dataset_properties_map = json.load(open(prop_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MAE,\n",
    "    MAPE,\n",
    "    MASE,\n",
    "    MSE,\n",
    "    MSIS,\n",
    "    ND,\n",
    "    NRMSE,\n",
    "    RMSE,\n",
    "    SMAPE,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(\n",
    "        quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronos Predictor\n",
    "\n",
    "For foundation models, we need to implement a wrapper containing the model and use the wrapper to generate predicitons.\n",
    "\n",
    "This is just meant to be a simple wrapper to get you started, feel free to use your own custom implementation to wrap any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike_gee/miniconda3/envs/gift/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from chronos import BaseChronosPipeline, ForecastType\n",
    "from gluonts.itertools import batcher\n",
    "from gluonts.model import Forecast\n",
    "from gluonts.model.forecast import QuantileForecast, SampleForecast\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    quantile_levels: Optional[List[float]] = None\n",
    "    forecast_keys: List[str] = field(init=False)\n",
    "    statsforecast_keys: List[str] = field(init=False)\n",
    "    intervals: Optional[List[int]] = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.forecast_keys = [\"mean\"]\n",
    "        self.statsforecast_keys = [\"mean\"]\n",
    "        if self.quantile_levels is None:\n",
    "            self.intervals = None\n",
    "            return\n",
    "\n",
    "        intervals = set()\n",
    "\n",
    "        for quantile_level in self.quantile_levels:\n",
    "            interval = round(200 * (max(quantile_level, 1 - quantile_level) - 0.5))\n",
    "            intervals.add(interval)\n",
    "            side = \"hi\" if quantile_level > 0.5 else \"lo\"\n",
    "            self.forecast_keys.append(str(quantile_level))\n",
    "            self.statsforecast_keys.append(f\"{side}-{interval}\")\n",
    "\n",
    "        self.intervals = sorted(intervals)\n",
    "\n",
    "\n",
    "class ChronosPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path,\n",
    "        num_samples: int,\n",
    "        prediction_length: int,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.pipeline = BaseChronosPipeline.from_pretrained(\n",
    "            model_path,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.prediction_length = prediction_length\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def predict(self, test_data_input, batch_size: int = 1024) -> List[Forecast]:\n",
    "        pipeline = self.pipeline\n",
    "        predict_kwargs = (\n",
    "            {\"num_samples\": self.num_samples}\n",
    "            if pipeline.forecast_type == ForecastType.SAMPLES\n",
    "            else {}\n",
    "        )\n",
    "        while True:\n",
    "            try:\n",
    "                # Generate forecast samples\n",
    "                forecast_outputs = []\n",
    "                for batch in tqdm(batcher(test_data_input, batch_size=batch_size)):\n",
    "                    context = [torch.tensor(entry[\"target\"]) for entry in batch]\n",
    "                    forecast_outputs.append(\n",
    "                        pipeline.predict(\n",
    "                            context,\n",
    "                            prediction_length=self.prediction_length,\n",
    "                            **predict_kwargs,\n",
    "                        ).numpy()\n",
    "                    )\n",
    "                forecast_outputs = np.concatenate(forecast_outputs)\n",
    "                break\n",
    "            except torch.cuda.OutOfMemoryError:\n",
    "                print(\n",
    "                    f\"OutOfMemoryError at batch_size {batch_size}, reducing to {batch_size // 2}\"\n",
    "                )\n",
    "                batch_size //= 2\n",
    "\n",
    "        # Convert forecast samples into gluonts Forecast objects\n",
    "        forecasts = []\n",
    "        for item, ts in zip(forecast_outputs, test_data_input):\n",
    "            forecast_start_date = ts[\"start\"] + len(ts[\"target\"])\n",
    "\n",
    "            if pipeline.forecast_type == ForecastType.SAMPLES:\n",
    "                forecasts.append(\n",
    "                    SampleForecast(samples=item, start_date=forecast_start_date)\n",
    "                )\n",
    "            elif pipeline.forecast_type == ForecastType.QUANTILES:\n",
    "                forecasts.append(\n",
    "                    QuantileForecast(\n",
    "                        forecast_arrays=item,\n",
    "                        forecast_keys=list(map(str, pipeline.quantiles)),\n",
    "                        start_date=forecast_start_date,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that we have our predictor class, we can use it to predict on the gift-eval benchmark datasets. We will use the `evaluate_model` function to evaluate the model. This function is a helper function to evaluate the model on the test data and return the results in a dictionary. We are going to follow the naming conventions explained in the [README](../README.md) file to store the results in a csv file called `all_results.csv` under the `results/chronos` folder.\n",
    "\n",
    "The first column in the csv file is the dataset config name which is a combination of the dataset name, frequency and the term:\n",
    "\n",
    "```python\n",
    "f\"{dataset_name}/{freq}/{term}\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class WarningFilter(logging.Filter):\n",
    "    def __init__(self, text_to_filter):\n",
    "        super().__init__()\n",
    "        self.text_to_filter = text_to_filter\n",
    "\n",
    "    def filter(self, record):\n",
    "        return self.text_to_filter not in record.getMessage()\n",
    "\n",
    "\n",
    "gts_logger = logging.getLogger(\"gluonts.model.forecast\")\n",
    "gts_logger.addFilter(\n",
    "    WarningFilter(\"The mean prediction is not stored in the forecast data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating chronos_bolt_base:   0%|          | 0/97 [00:00<?, ?dataset/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "7it [04:38, 39.80s/it]\n",
      "6460it [01:50, 58.66it/s]\n",
      "Evaluating chronos_bolt_base:   1%|          | 1/97 [06:37<10:35:53, 397.44s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.65s/it]\n",
      "646it [00:00, 1142.16it/s]\n",
      "Evaluating chronos_bolt_base:   2%|▏         | 2/97 [06:43<4:24:33, 167.09s/dataset] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [04:22, 43.83s/it]\n",
      "6137it [00:12, 511.19it/s]\n",
      "Evaluating chronos_bolt_base:   3%|▎         | 3/97 [11:19<5:39:43, 216.84s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.28s/it]\n",
      "90it [00:00, 965.05it/s]\n",
      "Evaluating chronos_bolt_base:   4%|▍         | 4/97 [11:21<3:24:34, 131.98s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:26, 26.35s/it]\n",
      "600it [00:01, 321.36it/s]\n",
      "Evaluating chronos_bolt_base:   5%|▌         | 5/97 [11:49<2:25:17, 94.76s/dataset] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:46, 23.36s/it]\n",
      "1092it [00:01, 843.99it/s]\n",
      "Evaluating chronos_bolt_base:   6%|▌         | 6/97 [12:38<1:59:55, 79.07s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.81s/it]\n",
      "312it [00:00, 1042.21it/s]\n",
      "Evaluating chronos_bolt_base:   7%|▋         | 7/97 [12:44<1:22:36, 55.07s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [32:05, 43.75s/it]\n",
      "45000it [01:26, 521.16it/s]\n",
      "Evaluating chronos_bolt_base:   8%|▊         | 8/97 [46:19<16:47:33, 679.25s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:12, 14.58s/it]\n",
      "5000it [00:04, 1082.74it/s]\n",
      "Evaluating chronos_bolt_base:   9%|▉         | 9/97 [47:38<12:00:54, 491.53s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [13:09, 43.84s/it]\n",
      "18000it [00:34, 515.78it/s]\n",
      "Evaluating chronos_bolt_base:  10%|█         | 10/97 [1:01:24<14:22:29, 594.82s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:30, 15.29s/it]\n",
      "2000it [00:01, 1063.34it/s]\n",
      "Evaluating chronos_bolt_base:  11%|█▏        | 11/97 [1:01:58<10:06:15, 422.97s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.27s/it]\n",
      "30it [00:00, 457.83it/s]\n",
      "Evaluating chronos_bolt_base:  12%|█▏        | 12/97 [1:01:59<6:57:42, 294.86s/dataset] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.69s/it]\n",
      "140it [00:00, 195.59it/s]\n",
      "Evaluating chronos_bolt_base:  13%|█▎        | 13/97 [1:02:07<4:51:07, 207.94s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.77s/it]\n",
      "42it [00:00, 679.26it/s]\n",
      "Evaluating chronos_bolt_base:  14%|█▍        | 14/97 [1:02:10<3:21:44, 145.84s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:29, 29.31s/it]\n",
      "630it [00:01, 503.85it/s]\n",
      "Evaluating chronos_bolt_base:  15%|█▌        | 15/97 [1:02:41<2:32:03, 111.26s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.44s/it]\n",
      "2674it [00:02, 963.94it/s]\n",
      "Evaluating chronos_bolt_base:  16%|█▋        | 16/97 [1:02:49<1:48:19, 80.24s/dataset] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.14s/it]\n",
      "266it [00:00, 915.24it/s]\n",
      "Evaluating chronos_bolt_base:  18%|█▊        | 17/97 [1:02:51<1:15:37, 56.71s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [05:37, 42.15s/it]\n",
      "7400it [02:27, 50.21it/s]\n",
      "Evaluating chronos_bolt_base:  19%|█▊        | 18/97 [1:10:57<4:04:25, 185.64s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:57, 28.52s/it]\n",
      "1850it [00:01, 990.62it/s]\n",
      "Evaluating chronos_bolt_base:  20%|█▉        | 19/97 [1:11:57<3:12:08, 147.80s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [05:25, 40.64s/it]\n",
      "7400it [00:40, 180.61it/s]\n",
      "Evaluating chronos_bolt_base:  21%|██        | 20/97 [1:18:04<4:34:12, 213.67s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.38s/it]\n",
      "1110it [00:00, 1204.73it/s]\n",
      "Evaluating chronos_bolt_base:  22%|██▏       | 21/97 [1:18:10<3:11:49, 151.44s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.89s/it]\n",
      "140it [00:01, 98.80it/s]\n",
      "Evaluating chronos_bolt_base:  23%|██▎       | 22/97 [1:18:18<2:15:25, 108.34s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.79it/s]\n",
      "21it [00:00, 860.20it/s]\n",
      "Evaluating chronos_bolt_base:  24%|██▎       | 23/97 [1:18:19<1:33:51, 76.10s/dataset] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.80s/it]\n",
      "140it [00:00, 303.83it/s]\n",
      "Evaluating chronos_bolt_base:  25%|██▍       | 24/97 [1:18:26<1:07:16, 55.30s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  9.14it/s]\n",
      "14it [00:00, 814.89it/s]\n",
      "Evaluating chronos_bolt_base:  26%|██▌       | 25/97 [1:18:26<46:40, 38.89s/dataset]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.92s/it]\n",
      "140it [00:01, 99.18it/s]\n",
      "Evaluating chronos_bolt_base:  27%|██▋       | 26/97 [1:18:34<35:02, 29.62s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.85it/s]\n",
      "21it [00:00, 689.06it/s]\n",
      "Evaluating chronos_bolt_base:  28%|██▊       | 27/97 [1:18:35<24:29, 21.00s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.85s/it]\n",
      "140it [00:00, 317.42it/s]\n",
      "Evaluating chronos_bolt_base:  29%|██▉       | 28/97 [1:18:42<19:15, 16.75s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  9.56it/s]\n",
      "14it [00:00, 831.05it/s]\n",
      "Evaluating chronos_bolt_base:  30%|██▉       | 29/97 [1:18:43<13:29, 11.90s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:32, 32.68s/it]\n",
      "826it [00:00, 938.91it/s]\n",
      "Evaluating chronos_bolt_base:  31%|███       | 30/97 [1:19:19<21:26, 19.21s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.44s/it]\n",
      "472it [00:00, 1229.88it/s]\n",
      "Evaluating chronos_bolt_base:  32%|███▏      | 31/97 [1:19:22<15:54, 14.45s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.66s/it]\n",
      "767it [00:00, 1034.86it/s]\n",
      "Evaluating chronos_bolt_base:  33%|███▎      | 32/97 [1:19:25<11:57, 11.04s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:18, 18.46s/it]\n",
      "420it [00:03, 123.27it/s]\n",
      "Evaluating chronos_bolt_base:  34%|███▍      | 33/97 [1:19:48<15:29, 14.52s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.80it/s]\n",
      "42it [00:00, 953.04it/s]\n",
      "Evaluating chronos_bolt_base:  35%|███▌      | 34/97 [1:19:49<10:58, 10.45s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:17, 17.26s/it]\n",
      "399it [00:00, 507.60it/s]\n",
      "Evaluating chronos_bolt_base:  36%|███▌      | 35/97 [1:20:07<13:19, 12.89s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.46s/it]\n",
      "540it [00:00, 1065.58it/s]\n",
      "Evaluating chronos_bolt_base:  37%|███▋      | 36/97 [1:20:13<10:51, 10.68s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [03:57, 39.57s/it]\n",
      "5400it [00:12, 437.21it/s]\n",
      "Evaluating chronos_bolt_base:  38%|███▊      | 37/97 [1:24:24<1:22:40, 82.68s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [03:11, 38.33s/it]\n",
      "4227it [00:05, 749.74it/s]\n",
      "Evaluating chronos_bolt_base:  39%|███▉      | 38/97 [1:27:42<1:55:33, 117.52s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.93s/it]\n",
      "414it [00:00, 855.22it/s]\n",
      "Evaluating chronos_bolt_base:  40%|████      | 39/97 [1:27:53<1:22:28, 85.31s/dataset] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [15:13, 19.43s/it]\n",
      "48000it [00:47, 1000.12it/s]\n",
      "Evaluating chronos_bolt_base:  41%|████      | 40/97 [1:44:06<5:34:02, 351.62s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [03:54,  9.77s/it]\n",
      "24000it [00:23, 1036.01it/s]\n",
      "Evaluating chronos_bolt_base:  42%|████▏     | 41/97 [1:48:29<5:03:35, 325.28s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:17, 17.34s/it]\n",
      "359it [00:00, 795.86it/s]\n",
      "Evaluating chronos_bolt_base:  43%|████▎     | 42/97 [1:48:48<3:33:47, 233.23s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [01:41,  4.42s/it]\n",
      "22974it [00:22, 1031.55it/s]\n",
      "Evaluating chronos_bolt_base:  44%|████▍     | 43/97 [1:50:57<3:01:56, 202.16s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.09s/it]\n",
      "807it [00:00, 935.57it/s]\n",
      "Evaluating chronos_bolt_base:  45%|████▌     | 44/97 [1:51:07<2:07:33, 144.41s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.19it/s]\n",
      "20it [00:00, 229.33it/s]\n",
      "Evaluating chronos_bolt_base:  46%|████▋     | 45/97 [1:51:09<1:27:58, 101.51s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.56it/s]\n",
      "7it [00:00, 585.06it/s]\n",
      "Evaluating chronos_bolt_base:  47%|████▋     | 46/97 [1:51:09<1:00:35, 71.28s/dataset] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.17it/s]\n",
      "20it [00:00, 633.24it/s]\n",
      "Evaluating chronos_bolt_base:  48%|████▊     | 47/97 [1:51:11<41:55, 50.32s/dataset]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:01, 40.35s/it]\n",
      "2740it [00:21, 128.33it/s]\n",
      "Evaluating chronos_bolt_base:  49%|████▉     | 48/97 [1:53:34<1:03:50, 78.18s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.87s/it]\n",
      "274it [00:00, 1074.56it/s]\n",
      "Evaluating chronos_bolt_base:  51%|█████     | 49/97 [1:53:37<44:25, 55.52s/dataset]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:58, 39.43s/it]\n",
      "2603it [00:05, 514.50it/s]\n",
      "Evaluating chronos_bolt_base:  52%|█████▏    | 50/97 [1:55:41<59:39, 76.15s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.37it/s]\n",
      "137it [00:00, 967.59it/s]\n",
      "Evaluating chronos_bolt_base:  53%|█████▎    | 51/97 [1:55:42<41:06, 53.62s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [25:29, 16.28s/it]\n",
      "96216it [01:29, 1079.23it/s]\n",
      "Evaluating chronos_bolt_base:  54%|█████▎    | 52/97 [2:22:54<6:35:28, 527.29s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.17it/s]\n",
      "20it [00:00, 467.95it/s]\n",
      "Evaluating chronos_bolt_base:  55%|█████▍    | 53/97 [2:22:56<4:30:59, 369.54s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 14.22it/s]\n",
      "2it [00:00, 250.97it/s]\n",
      "Evaluating chronos_bolt_base:  56%|█████▌    | 54/97 [2:22:56<3:05:30, 258.84s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.93it/s]\n",
      "14it [00:00, 724.02it/s]\n",
      "Evaluating chronos_bolt_base:  57%|█████▋    | 55/97 [2:22:57<2:07:01, 181.46s/dataset]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_length: 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike_gee/miniconda3/envs/gift/lib/python3.11/site-packages/chronos/chronos_bolt.py:527: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
      "  warnings.warn(msg)\n",
      "5it [36:27, 437.55s/it]\n",
      "Evaluating chronos_bolt_base:  57%|█████▋    | 55/97 [2:59:26<2:17:01, 195.75s/dataset]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     47\u001b[39m dataset = Dataset(name=row[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m], term=row[\u001b[33m\"\u001b[39m\u001b[33mterm\u001b[39m\u001b[33m\"\u001b[39m], verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     49\u001b[39m predictor = ChronosPredictor(\n\u001b[32m     50\u001b[39m     model_path=\u001b[33m\"\u001b[39m\u001b[33mamazon/chronos-bolt-base\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m     num_samples=\u001b[32m20\u001b[39m,\n\u001b[32m     52\u001b[39m     prediction_length=dataset.prediction_length,\n\u001b[32m     53\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m res = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask_invalid_label\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan_forecast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseasonality\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseasonality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_path, \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m, newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[32m     67\u001b[39m     writer = csv.writer(csvfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/gluonts/model/evaluation.py:260\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, test_data, metrics, axis, batch_size, mask_invalid_label, allow_nan_forecast, seasonality)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_model\u001b[39m(\n\u001b[32m    237\u001b[39m     model: Predictor,\n\u001b[32m    238\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m     seasonality: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    246\u001b[39m ) -> pd.DataFrame:\n\u001b[32m    247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    Evaluate ``model`` when applied to ``test_data``, according to ``metrics``.\u001b[39;00m\n\u001b[32m    249\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m    Return results as a Pandas ``DataFrame``.\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     forecasts = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluate_forecasts(\n\u001b[32m    263\u001b[39m         forecasts=forecasts,\n\u001b[32m    264\u001b[39m         test_data=test_data,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         seasonality=seasonality,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mChronosPredictor.predict\u001b[39m\u001b[34m(self, test_data_input, batch_size)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(batcher(test_data_input, batch_size=batch_size)):\n\u001b[32m     69\u001b[39m     context = [torch.tensor(entry[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m     70\u001b[39m     forecast_outputs.append(\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m         \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpredict_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.numpy()\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     77\u001b[39m forecast_outputs = np.concatenate(forecast_outputs)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/chronos/chronos_bolt.py:546\u001b[39m, in \u001b[36mChronosBoltPipeline.predict\u001b[39m\u001b[34m(self, context, prediction_length, limit_prediction_length)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m    545\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m         prediction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.quantile_preds.to(context_tensor)\n\u001b[32m    550\u001b[39m     predictions.append(prediction)\n\u001b[32m    551\u001b[39m     remaining -= prediction.shape[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/chronos/chronos_bolt.py:313\u001b[39m, in \u001b[36mChronosBoltModelForForecasting.forward\u001b[39m\u001b[34m(self, context, mask, target, target_mask)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    306\u001b[39m     context: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m     target_mask: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    310\u001b[39m ) -> ChronosBoltOutput:\n\u001b[32m    311\u001b[39m     batch_size = context.size(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     hidden_states, loc_scale, input_embeds, attention_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     sequence_output = \u001b[38;5;28mself\u001b[39m.decode(input_embeds, attention_mask, hidden_states)\n\u001b[32m    318\u001b[39m     quantile_preds_shape = (\n\u001b[32m    319\u001b[39m         batch_size,\n\u001b[32m    320\u001b[39m         \u001b[38;5;28mself\u001b[39m.num_quantiles,\n\u001b[32m    321\u001b[39m         \u001b[38;5;28mself\u001b[39m.chronos_config.prediction_length,\n\u001b[32m    322\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/chronos/chronos_bolt.py:297\u001b[39m, in \u001b[36mChronosBoltModelForForecasting.encode\u001b[39m\u001b[34m(self, context, mask)\u001b[39m\n\u001b[32m    288\u001b[39m     input_embeds = torch.cat([input_embeds, reg_embeds], dim=-\u001b[32m2\u001b[39m)\n\u001b[32m    289\u001b[39m     attention_mask = torch.cat(\n\u001b[32m    290\u001b[39m         [\n\u001b[32m    291\u001b[39m             attention_mask.to(\u001b[38;5;28mself\u001b[39m.dtype),\n\u001b[32m   (...)\u001b[39m\u001b[32m    294\u001b[39m         dim=-\u001b[32m1\u001b[39m,\n\u001b[32m    295\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m encoder_outputs[\u001b[32m0\u001b[39m], loc_scale, input_embeds, attention_mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1124\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1107\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1108\u001b[39m         layer_module.forward,\n\u001b[32m   1109\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1121\u001b[39m         cache_position,\n\u001b[32m   1122\u001b[39m     )\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:729\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    726\u001b[39m     attention_outputs = attention_outputs + cross_attention_outputs[\u001b[32m2\u001b[39m:]\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hidden_states.dtype == torch.float16:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:343\u001b[39m, in \u001b[36mT5LayerFF.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[32m    342\u001b[39m     forwarded_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     forwarded_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(forwarded_states)\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:288\u001b[39m, in \u001b[36mT5DenseActDense.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.act(hidden_states)\n\u001b[32m    290\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gift/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from gluonts.model import evaluate_model\n",
    "from gift_eval.data import Dataset\n",
    "\n",
    "model_name = \"chronos_bolt_base\"\n",
    "\n",
    "output_dir = Path(\"..\") / \"results\" / model_name / split_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_file = \"all_results.csv\"\n",
    "\n",
    "csv_path = output_dir / output_file\n",
    "\n",
    "pretty_names = {\n",
    "    \"saugeenday\": \"saugeen\",\n",
    "    \"temperature_rain_with_missing\": \"temperature_rain\",\n",
    "    \"kdd_cup_2018_with_missing\": \"kdd_cup_2018\",\n",
    "    \"car_parts_with_missing\": \"car_parts\",\n",
    "}\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "kwargs = {\"desc\": f\"Evaluating {model_name}\", \"total\": len(df), \"unit\": \"dataset\"}\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), **kwargs):\n",
    "    dataset = Dataset(name=row[\"name\"], term=row[\"term\"], verbose=False)\n",
    "\n",
    "    predictor = ChronosPredictor(\n",
    "        model_path=\"amazon/chronos-bolt-base\",\n",
    "        num_samples=20,\n",
    "        prediction_length=dataset.prediction_length,\n",
    "    )\n",
    "\n",
    "    res = evaluate_model(\n",
    "        predictor,\n",
    "        test_data=dataset.test_data,\n",
    "        metrics=metrics,\n",
    "        batch_size=1024,\n",
    "        axis=None,\n",
    "        mask_invalid_label=True,\n",
    "        allow_nan_forecast=False,\n",
    "        seasonality=dataset.seasonality,\n",
    "    )\n",
    "\n",
    "    with open(csv_path, \"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(\n",
    "            [\n",
    "                dataset.config,\n",
    "                model_name,\n",
    "                res[\"MSE[mean]\"][0],\n",
    "                res[\"MSE[0.5]\"][0],\n",
    "                res[\"MAE[0.5]\"][0],\n",
    "                res[\"MASE[0.5]\"][0],\n",
    "                res[\"MAPE[0.5]\"][0],\n",
    "                res[\"sMAPE[0.5]\"][0],\n",
    "                res[\"MSIS\"][0],\n",
    "                res[\"RMSE[mean]\"][0],\n",
    "                res[\"NRMSE[mean]\"][0],\n",
    "                res[\"ND[0.5]\"][0],\n",
    "                res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                row[\"domain\"],\n",
    "                row[\"num_variates\"],\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Running the above cell will generate a csv file called `all_results.csv` under the `results/chronos` folder containing the results for the Chronos model on the gift-eval benchmark. We can display the csv file using the follow code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"../results/{model_name}/all_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretraining dataset information CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "split = \"pretrain\"\n",
    "info_path = Path(\"resources\") / split / \"info.csv\"\n",
    "df = pd.read_csv(info_path)\n",
    "\n",
    "print(f\"Reading {len(df)} {split} datasets...\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on each name-term combination in the pretraining split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"..\") / \"results\" / model_name / split\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_file_path = output_dir / \"all_results.csv\"\n",
    "\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "kwargs = {\n",
    "    \"desc\": f\"Evaluting {model_name}\",\n",
    "    \"total\": len(df),\n",
    "    \"unit\": \"dataset\",\n",
    "}\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), **kwargs):\n",
    "    dataset = Dataset(name=row[\"name\"], term=row[\"term\"])\n",
    "\n",
    "    predictor = ChronosPredictor(\n",
    "        model_path=\"amazon/chronos-bolt-base\",\n",
    "        num_samples=20,\n",
    "        prediction_length=dataset.prediction_length,\n",
    "    )\n",
    "\n",
    "    res = evaluate_model(\n",
    "        predictor,\n",
    "        test_data=dataset.test_data,\n",
    "        metrics=metrics,\n",
    "        batch_size=1024,\n",
    "        axis=None,\n",
    "        mask_invalid_label=True,\n",
    "        allow_nan_forecast=False,\n",
    "        seasonality=dataset.seasonality,\n",
    "    )\n",
    "\n",
    "    with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(\n",
    "            [\n",
    "                dataset.config,\n",
    "                model_name,\n",
    "                res[\"MSE[mean]\"][0],\n",
    "                res[\"MSE[0.5]\"][0],\n",
    "                res[\"MAE[0.5]\"][0],\n",
    "                res[\"MASE[0.5]\"][0],\n",
    "                res[\"MAPE[0.5]\"][0],\n",
    "                res[\"sMAPE[0.5]\"][0],\n",
    "                res[\"MSIS\"][0],\n",
    "                res[\"RMSE[mean]\"][0],\n",
    "                res[\"NRMSE[mean]\"][0],\n",
    "                res[\"ND[0.5]\"][0],\n",
    "                res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "            ]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
