{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350dd11a",
   "metadata": {},
   "source": [
    "# GluonTS: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4fd7d",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to tune hyperparameters in [GluonTS](https://ts.gluon.ai/stable/index.html) using [Optuna](https://optuna.org/). See [here](https://ts.gluon.ai/stable/tutorials/advanced_topics/hp_tuning_with_optuna.html) for the original tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b876046",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce69f5f",
   "metadata": {},
   "source": [
    "Load the M4 Hourly dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aad51ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:25:25.672089Z",
     "iopub.status.busy": "2024-05-31T18:25:25.671889Z",
     "iopub.status.idle": "2024-05-31T18:25:26.340645Z",
     "shell.execute_reply": "2024-05-31T18:25:26.339920Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from gluonts.dataset.repository import get_dataset\n",
    "from gluonts.dataset.util import to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1daae219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:25:26.343531Z",
     "iopub.status.busy": "2024-05-31T18:25:26.343255Z",
     "iopub.status.idle": "2024-05-31T18:25:27.543732Z",
     "shell.execute_reply": "2024-05-31T18:25:27.542981Z"
    }
   },
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository import get_dataset\n",
    "\n",
    "dataset = get_dataset(\"m4_hourly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc0eb5",
   "metadata": {},
   "source": [
    "Extract the training split, test split, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f4de2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 414\n",
      "Number of test examples: 414\n",
      "Recommended prediction horizon: 48\n",
      "Frequency of the time series: H\n"
     ]
    }
   ],
   "source": [
    "training_dataset = dataset.train\n",
    "test_dataset = dataset.test\n",
    "metadata = dataset.metadata\n",
    "\n",
    "print(f\"Number of training examples: {len(training_dataset)}\")\n",
    "print(f\"Number of test examples: {len(test_dataset)}\")\n",
    "print(f\"Recommended prediction horizon: {dataset.metadata.prediction_length}\")\n",
    "print(f\"Frequency of the time series: {dataset.metadata.freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fdfecb",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c9ec2",
   "metadata": {},
   "source": [
    "In this example, we'll optimize the following hyperparameters for a [DeepAR estimator](https://ts.gluon.ai/stable/api/gluonts/gluonts.torch.html?highlight=deeparestimator#gluonts.torch.DeepAREstimator).\n",
    "- `num_layers`\n",
    "- `hidden_size` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a7462",
   "metadata": {},
   "source": [
    "1. Define a function to convert a GluonTS `DataEntry` (a dict representing a time series) into a pandas [`DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b628d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gluonts.dataset.common import DataEntry\n",
    "\n",
    "\n",
    "def dataentry_to_dataframe(entry: DataEntry) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a GluonTS DataEntry to a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        entry (DataEntry): A dictionary representing a time series. Must\n",
    "            contain a `start` field and a `target` field.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input time series represented as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        entry[\"target\"],\n",
    "        columns=[entry.get(\"item_id\")],\n",
    "        index=pd.period_range(\n",
    "            start=entry[\"start\"],\n",
    "            periods=len(entry[\"target\"]),\n",
    "            freq=entry[\"start\"].freq,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5f29f",
   "metadata": {},
   "source": [
    "2. Define a class that'll be used during the tuning process. This class can be configured with the dataset, prediction length, frequency, and the metric to be used for evaluting the model.\n",
    "\n",
    "Here's what we'll do in each method:\n",
    " - `__init__`:\n",
    "   - Initialize the objective to optimize and split the dataset into two parts using GluonTS's [`split`](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.split.html?highlight=split#module-gluonts.dataset.split) method:\n",
    "     - `validation_input`: the input part used in validation\n",
    "     - `validation_label`: the label part used in validation\n",
    " - `get_params`:\n",
    "   - We'll define what hyperparameters will be tuned within given range\n",
    " - `__call__`:\n",
    "   - We'll define how the `DeepAREstimator` is used in training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2f4ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.split import split\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "from typing import Iterable\n",
    "\n",
    "\n",
    "class DeepARTuningObjective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Iterable[DataEntry],\n",
    "        prediction_length: int,\n",
    "        freq: str,\n",
    "        metric_type: str = \"mean_wQuantileLoss\",\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.prediction_length = prediction_length\n",
    "        self.freq = freq\n",
    "        self.metric_type = metric_type\n",
    "        self.train, test_template = split(dataset, offset=-self.prediction_length)\n",
    "\n",
    "        # ? For your case, can you just pass the val set directly?\n",
    "        validation = test_template.generate_instances(\n",
    "            prediction_length=prediction_length\n",
    "        )\n",
    "        self.validation_input = [entry[0] for entry in validation]\n",
    "        self.validation_label = [\n",
    "            dataentry_to_dataframe(entry[1]) for entry in validation\n",
    "        ]\n",
    "\n",
    "    def get_params(self, trial) -> dict:\n",
    "        \"\"\"\n",
    "        Get the parameters for the DeepAR model based on the trial.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"num_layers\": trial.suggest_int(\"num_layers\", 1, 5),\n",
    "            \"hidden_size\": trial.suggest_int(\"hidden_size\", 10, 50),\n",
    "        }\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        params = self.get_params(trial)\n",
    "\n",
    "        # Initialize new DeepAR estimator with the suggested parameters\n",
    "        estimator = DeepAREstimator(\n",
    "            num_layers=params[\"num_layers\"],\n",
    "            hidden_size=params[\"hidden_size\"],\n",
    "            prediction_length=self.prediction_length,\n",
    "            freq=self.freq,\n",
    "            trainer_kwargs={\n",
    "                \"enable_progress_bar\": False,\n",
    "                \"enable_model_summary\": False,\n",
    "                \"max_epochs\": 10,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Train estimator\n",
    "        predictor = estimator.train(self.train, cache_data=True)\n",
    "\n",
    "        # Generate forecasts\n",
    "        forecasts = list(predictor.predict(self.validation_input))\n",
    "\n",
    "        # Create new evaluator\n",
    "        evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "\n",
    "        # Aggregate metrics across all time series\n",
    "        agg_metrics, item_metrics = evaluator(\n",
    "            self.validation_label,\n",
    "            forecasts,\n",
    "            num_series=len(self.dataset),\n",
    "        )\n",
    "\n",
    "        return agg_metrics[self.metric_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01712e01",
   "metadata": {},
   "source": [
    "3. Perform hyperparameter tuning using the Optuna tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d99387e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 02:10:36,801] A new study created in memory with name: no-name-785e4dfd-4e03-4c66-b293-24cc0a5583f6\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.85335 (best 5.85335), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.85335 (best 5.85335), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.27758 (best 5.27758), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.27758 (best 5.27758), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 5.04082 (best 5.04082), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 5.04082 (best 5.04082), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' reached 4.70819 (best 4.70819), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 4.70819 (best 4.70819), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' reached 4.54149 (best 4.54149), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 4.54149 (best 4.54149), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' reached 4.40770 (best 4.40770), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 4.40770 (best 4.40770), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' reached 4.36065 (best 4.36065), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 4.36065 (best 4.36065), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' reached 4.21879 (best 4.21879), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 4.21879 (best 4.21879), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 455.59it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:11:17,056] Trial 0 finished with value: 0.050682921074935 and parameters: {'num_layers': 4, 'hidden_size': 18}. Best is trial 0 with value: 0.050682921074935.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.55287 (best 5.55287), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.55287 (best 5.55287), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 4.94810 (best 4.94810), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 4.94810 (best 4.94810), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' reached 4.81259 (best 4.81259), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 4.81259 (best 4.81259), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 4.49894 (best 4.49894), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 4.49894 (best 4.49894), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' reached 4.19176 (best 4.19176), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 4.19176 (best 4.19176), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' reached 3.98396 (best 3.98396), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 3.98396 (best 3.98396), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' reached 3.95016 (best 3.95016), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 3.95016 (best 3.95016), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' reached 3.93432 (best 3.93432), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 3.93432 (best 3.93432), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_6\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 489.16it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:11:47,168] Trial 1 finished with value: 0.13770550406335694 and parameters: {'num_layers': 2, 'hidden_size': 43}. Best is trial 0 with value: 0.050682921074935.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.95783 (best 5.95783), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.95783 (best 5.95783), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.41481 (best 5.41481), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.41481 (best 5.41481), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' reached 5.00333 (best 5.00333), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 5.00333 (best 5.00333), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 4.62296 (best 4.62296), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 4.62296 (best 4.62296), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' reached 4.45596 (best 4.45596), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 4.45596 (best 4.45596), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' reached 4.45459 (best 4.45459), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 4.45459 (best 4.45459), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_7\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 436.56it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:12:19,096] Trial 2 finished with value: 0.09732490315733326 and parameters: {'num_layers': 3, 'hidden_size': 15}. Best is trial 0 with value: 0.050682921074935.\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.53546 (best 5.53546), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.53546 (best 5.53546), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 4.64754 (best 4.64754), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 4.64754 (best 4.64754), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' reached 4.44093 (best 4.44093), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 4.44093 (best 4.44093), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' reached 4.26058 (best 4.26058), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 4.26058 (best 4.26058), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' reached 4.22504 (best 4.22504), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 4.22504 (best 4.22504), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' reached 4.07652 (best 4.07652), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 4.07652 (best 4.07652), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 477.99it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:12:38,297] Trial 3 finished with value: 0.04892085096424612 and parameters: {'num_layers': 1, 'hidden_size': 42}. Best is trial 3 with value: 0.04892085096424612.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.77975 (best 5.77975), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.77975 (best 5.77975), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.25418 (best 5.25418), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.25418 (best 5.25418), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 4.89672 (best 4.89672), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 4.89672 (best 4.89672), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' reached 4.86081 (best 4.86081), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 4.86081 (best 4.86081), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' reached 4.61366 (best 4.61366), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 4.61366 (best 4.61366), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' reached 4.52841 (best 4.52841), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 4.52841 (best 4.52841), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' reached 4.42134 (best 4.42134), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 4.42134 (best 4.42134), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' reached 4.32678 (best 4.32678), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 4.32678 (best 4.32678), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 482.36it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:13:10,114] Trial 4 finished with value: 0.04555586015714282 and parameters: {'num_layers': 3, 'hidden_size': 18}. Best is trial 4 with value: 0.04555586015714282.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.74589 (best 5.74589), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.74589 (best 5.74589), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.13550 (best 5.13550), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.13550 (best 5.13550), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' reached 5.01497 (best 5.01497), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 5.01497 (best 5.01497), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 4.51861 (best 4.51861), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 4.51861 (best 4.51861), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' reached 4.37031 (best 4.37031), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 4.37031 (best 4.37031), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' reached 4.12344 (best 4.12344), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 4.12344 (best 4.12344), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_10\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 454.17it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:13:54,087] Trial 5 finished with value: 0.06546732776793547 and parameters: {'num_layers': 3, 'hidden_size': 45}. Best is trial 4 with value: 0.04555586015714282.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.95882 (best 5.95882), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.95882 (best 5.95882), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.23835 (best 5.23835), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.23835 (best 5.23835), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' reached 4.82432 (best 4.82432), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 4.82432 (best 4.82432), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 4.45357 (best 4.45357), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 4.45357 (best 4.45357), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' reached 4.27884 (best 4.27884), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 4.27884 (best 4.27884), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_11\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 481.87it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:14:19,315] Trial 6 finished with value: 0.08041790875261241 and parameters: {'num_layers': 2, 'hidden_size': 17}. Best is trial 4 with value: 0.04555586015714282.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.64655 (best 5.64655), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.64655 (best 5.64655), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.15954 (best 5.15954), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.15954 (best 5.15954), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' reached 4.87199 (best 4.87199), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 4.87199 (best 4.87199), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' reached 4.51449 (best 4.51449), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 4.51449 (best 4.51449), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' reached 4.47094 (best 4.47094), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 4.47094 (best 4.47094), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' reached 4.46664 (best 4.46664), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 4.46664 (best 4.46664), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' reached 4.30660 (best 4.30660), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 4.30660 (best 4.30660), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_12\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 476.80it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:14:59,076] Trial 7 finished with value: 0.039687599500918117 and parameters: {'num_layers': 4, 'hidden_size': 24}. Best is trial 7 with value: 0.039687599500918117.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.59973 (best 5.59973), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.59973 (best 5.59973), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.41708 (best 5.41708), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.41708 (best 5.41708), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' reached 5.10404 (best 5.10404), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 5.10404 (best 5.10404), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 4.58963 (best 4.58963), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 4.58963 (best 4.58963), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' reached 4.51282 (best 4.51282), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 4.51282 (best 4.51282), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' reached 4.42880 (best 4.42880), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 4.42880 (best 4.42880), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' reached 4.11216 (best 4.11216), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 4.11216 (best 4.11216), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' reached 4.11108 (best 4.11108), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 4.11108 (best 4.11108), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' reached 4.07247 (best 4.07247), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 4.07247 (best 4.07247), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_13\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 482.26it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:15:54,071] Trial 8 finished with value: 0.08256725714625528 and parameters: {'num_layers': 4, 'hidden_size': 50}. Best is trial 7 with value: 0.039687599500918117.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "INFO: Epoch 0, global step 50: 'train_loss' reached 5.73056 (best 5.73056), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 5.73056 (best 5.73056), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "INFO: Epoch 1, global step 100: 'train_loss' reached 5.36052 (best 5.36052), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 5.36052 (best 5.36052), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "INFO: Epoch 2, global step 150: 'train_loss' reached 5.01475 (best 5.01475), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 5.01475 (best 5.01475), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "INFO: Epoch 3, global step 200: 'train_loss' reached 4.72375 (best 4.72375), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 4.72375 (best 4.72375), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "INFO: Epoch 4, global step 250: 'train_loss' reached 4.42687 (best 4.42687), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 4.42687 (best 4.42687), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "INFO: Epoch 7, global step 400: 'train_loss' reached 4.38240 (best 4.38240), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 4.38240 (best 4.38240), saving model to 'c:\\\\Users\\\\Mike\\\\vscode\\\\gift-eval\\\\notebooks\\\\lightning_logs\\\\version_14\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Running evaluation: 100%|██████████| 414/414 [00:00<00:00, 445.54it/s]\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "c:\\Users\\Mike\\anaconda3\\envs\\gift\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "[I 2025-06-30 02:16:27,818] Trial 9 finished with value: 0.04126687355215323 and parameters: {'num_layers': 3, 'hidden_size': 21}. Best is trial 7 with value: 0.039687599500918117.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for hyperparameter tuning: 351.02 seconds\n",
      "Best metric: 0.039687599500918117\n",
      "Best hyperparameters found:\n",
      "num_layers: 4\n",
      "hidden_size: 24\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import time\n",
    "import torch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(\n",
    "    DeepARTuningObjective(\n",
    "        training_dataset,\n",
    "        prediction_length=metadata.prediction_length,\n",
    "        freq=metadata.freq,\n",
    "    ),\n",
    "    n_trials=10,\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken for hyperparameter tuning: {(end_time - start_time):.2f} seconds\")\n",
    "\n",
    "print(f\"Best metric: {study.best_value}\")\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(\"Best hyperparameters found:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf09b59",
   "metadata": {},
   "source": [
    "4. Now that we've finished hyperparameter tuning, we can use the best hyperparameters to re-train the model on the whole training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca378a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final model with the best hyperparameters\n",
    "estimator = DeepAREstimator(\n",
    "    num_layers=best_trial.params[\"num_layers\"],\n",
    "    hidden_size=best_trial.params[\"hidden_size\"],\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=100,\n",
    "    freq=dataset.metadata.freq,\n",
    "    trainer_kwargs={\n",
    "        \"enable_progress_bar\": False,\n",
    "        \"enable_model_summary\": False,\n",
    "        \"max_epochs\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "predictor = estimator.train(dataset.train, cache_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
